{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Chargement des librairies nécessaires\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(gridExtra)\n",
    "library(GGally)\n",
    "library(plotly)\n",
    "library(corrplot)\n",
    "library(reshape2)\n",
    "library(FactoMineR) \n",
    "library(factoextra)\n",
    "library(glmnet) \n",
    "library(ggfortify)\n",
    "library(pROC)\n",
    "library(ROCR)\n",
    "library(repr)\n",
    "library(caret)\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "set.seed(1234)\n",
    "\n",
    "## GRAPH SETTINGS ##\n",
    "# Save original parameters (optional)\n",
    "original_par <- par(no.readonly = TRUE)\n",
    "\n",
    "# Set global scaling factors (1.5x default size)\n",
    "par(\n",
    "  cex.lab = 1.5,   # Axis labels\n",
    "  cex.axis = 1.5,  # Axis text (tick labels)\n",
    "  cex.main = 1.5,  # Main title\n",
    "  cex.sub = 1.5    # Subtitle\n",
    ")\n",
    "\n",
    "# Define a custom theme with larger fonts\n",
    "custom_theme <- theme(\n",
    "  text = element_text(size = 16),            # Global text size\n",
    "  axis.title = element_text(size = 18),      # Axis labels\n",
    "  axis.text = element_text(size = 14),       # Axis tick labels\n",
    "  plot.title = element_text(size = 20),      # Main title\n",
    "  plot.subtitle = element_text(size = 16)    # Subtitle\n",
    ")\n",
    "\n",
    "# Apply the theme to all future plots\n",
    "theme_set(custom_theme)\n",
    "\n",
    "\n",
    "## DATA LOADING & PROCESSING ##\n",
    "# Load data\n",
    "path <- \"../../\" # modifier le nombre de ../ si nécessaire\n",
    "gym <- read.table(paste(path, \"gym_members_exercise_tracking.csv\", sep = \"\"),\n",
    "                    sep = \",\", header = TRUE)\n",
    "\n",
    "gym[,'Gender'] <- as.factor(gym[,'Gender'])\n",
    "gym[,'Workout_Type'] <- as.factor(gym[,'Workout_Type'])\n",
    "gym[,'Experience_Level'] <- as.factor(gym[,'Experience_Level'])\n",
    "gym[,'Workout_Frequency..days.week.'] <- as.factor(gym[,'Workout_Frequency..days.week.'])\n",
    "\n",
    "gym[, \"Weight..kg.\"] <- log(gym[,\"Weight..kg.\"])\n",
    "\n",
    "max_fat <- max(gym[,\"Fat_Percentage\"])\n",
    "gym[, \"Fat_Percentage\"] <- sqrt((max_fat + 1) - gym[,\"Fat_Percentage\"])\n",
    "\n",
    "# renome les variables Weight..kg. et BMI en LWeight et LBMI\n",
    "names(gym)[names(gym) == \"Weight..kg.\"] <- \"LWeight\"\n",
    "names(gym)[names(gym) == \"Fat_Percentage\"] <- \"SFat_Percentage\"\n",
    "\n",
    "gym <- gym %>% select(-c(BMI))\n",
    "\n",
    "# divide data into training and testing sets for experience level\n",
    "trainIndex <- createDataPartition(gym$Experience_Level, p = .8, \n",
    "                                  list = FALSE, \n",
    "                                  times = 1)\n",
    "gym_train <- gym[ trainIndex,]\n",
    "gym_test  <- gym[-trainIndex,]\n",
    "\n",
    "# Normalize the data\n",
    "gym_train_scaled = gym_train\n",
    "scaler <- scale(gym_train[,-c(2,10,13,14)])\n",
    "\n",
    "# Extract the center and scale attributes\n",
    "center <- attr(scaler, \"scaled:center\")\n",
    "scale <- attr(scaler, \"scaled:scale\")\n",
    "\n",
    "gym_train_scaled[,-c(2,10,13,14)] <- scale(gym_train[,-c(2,10,13,14)], center = center, scale = scale)\n",
    "\n",
    "gym_test_scaled = gym_test\n",
    "gym_test_scaled[,-c(2,10,13,14)] <- scale(gym_test[,-c(2,10,13,14)], center = center, scale = scale)\n",
    "\n",
    "\n",
    "cat(\"Data loaded and preprocessed\")\n",
    "\n",
    "\n",
    "## FUNCTION DEFINITIONS ##\n",
    "\n",
    "# Function to plot residuals\n",
    "# x: predicted values\n",
    "# y: residuals\n",
    "gplot.res <- function(x, y, titre = \"titre\"){\n",
    "    ggplot(data.frame(x=x, y=y),aes(x,y))+\n",
    "    geom_point(col = \"blue\")+#xlim(0, 250)+ylim(-155, 155)+\n",
    "    ylab(\"Résidus\")+ xlab(\"Valeurs prédites\")+\n",
    "    ggtitle(titre)+\n",
    "    geom_hline(yintercept = 0,col=\"green\")\n",
    "}\n",
    "\n",
    "# Function to plot ROC curve\n",
    "# model: model to evaluate\n",
    "# data: data to evaluate\n",
    "# title: title of the plot\n",
    "plot_roc <- function(model, data, title = \"ROC curve\"){\n",
    "    pred <- predict(model, data, type = \"response\")\n",
    "    roc <- roc(data$Experience_Level, pred)\n",
    "    auc <- round(auc(roc), 2)\n",
    "    plot(roc, main = title)\n",
    "    text(0.8, 0.2, paste(\"AUC = \", auc), cex = 1.5)\n",
    "}\n",
    "\n",
    "# Function that compute R2\n",
    "\n",
    "# compute_R2 <- function(model, newdata = NA){\n",
    "#   if newdata == NA{\n",
    "#     residuals <- predict(model)\n",
    "#       rss <- sum()\n",
    "#       tss <- \n",
    "# }\n",
    "#   res.tree.cal.cp_high.test <- predict(tree.reg.cal.cp_high, newdata = gym_test)\n",
    "#   mse_test_cal_cp_high <- mean((res.tree.cal.cp_high.test - gym_train[,\"Calories_Burned\"])^2)\n",
    "#   rss_cal_cp_high <- sum((res.tree.cal.cp_high.test - gym_test[,\"Calories_Burned\"])^2)\n",
    "#   tss_cal_cp_high <- sum((gym_test[,\"Calories_Burned\"] - mean(gym_test[,\"Calories_Burned\"]))^2)\n",
    "#   r2_test_cal_cp_high <- 1 - rss_cal_cp_high / tss_cal_cp_high\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(gym_train_scaled)\n",
    "summary(gym_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART & Agregation\n",
    "### Classification Trees\n",
    "\n",
    "- Fit a classification tree.\n",
    "- Prune the tree using cross-validation.\n",
    "- Plot: Decision tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fit a regression tree model\n",
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "library(MLmetrics)\n",
    "\n",
    "# Fit a regression tree model for Experience_Level using the training set\n",
    "tree.reg.exp <- rpart(Experience_Level ~ ., data = gym_train, control=rpart.control(cp=0.0001))\n",
    "\n",
    "options(repr.plot.width=18, repr.plot.height=12)\n",
    "# Plot the tree\n",
    "rpart.plot(tree.reg.exp, extra = 101, type = 3, under = TRUE, cex = 0.8, tweak = 1)\n",
    "\n",
    "# Convert the target to binary for ROC analysis\n",
    "# Here we're treating Experience_Level as a binary classification problem\n",
    "# First, get predicted probabilities for each class\n",
    "pred_exp_tree_test <- predict(tree.reg.exp, gym_test, type = \"prob\")\n",
    "pred_exp_tree_train <- predict(tree.reg.exp, gym_train, type = \"prob\")\n",
    "\n",
    "# Get actual classes and convert to numeric matrix for MultiLogLoss\n",
    "actual_classes <- gym_test$Experience_Level\n",
    "actual_matrix <- model.matrix(~actual_classes-1)\n",
    "\n",
    "# Calculate log loss using MultiLogLoss from MLmetrics\n",
    "logloss_value <- MultiLogLoss(y_pred = pred_exp_tree_test, y_true = actual_matrix)\n",
    "\n",
    "# Calculate confusion matrix for test set\n",
    "pred_classes_test <- predict(tree.reg.exp, gym_test, type=\"class\")\n",
    "conf_matrix_test <- confusionMatrix(pred_classes_test, gym_test$Experience_Level)\n",
    "\n",
    "cat(\"Test Set Performance:\\n\")\n",
    "cat(\"- Accuracy:\", round(conf_matrix_test$overall[\"Accuracy\"], 4), \"\\n\")\n",
    "cat(\"- Log loss:\", round(logloss_value, 4), \"(lower is better)\\n\")\n",
    "cat(\"- Confusion Matrix:\\n\")\n",
    "print(conf_matrix_test$table)\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Compute the metrics for the gym_train set\n",
    "# Calculate confusion matrix for training set\n",
    "pred_classes_train <- predict(tree.reg.exp, gym_train, type=\"class\")\n",
    "conf_matrix_train <- confusionMatrix(pred_classes_train, gym_train$Experience_Level)\n",
    "\n",
    "# Get actual classes and convert to numeric matrix for MultiLogLoss\n",
    "actual_classes_train <- gym_train$Experience_Level\n",
    "actual_matrix_train <- model.matrix(~actual_classes_train-1)\n",
    "\n",
    "# Calculate log loss using MultiLogLoss from MLmetrics\n",
    "logloss_value_train <- MultiLogLoss(y_pred = pred_exp_tree_train, y_true = actual_matrix_train)\n",
    "\n",
    "\n",
    "cat(\"Training Set Performance:\\n\")\n",
    "cat(\"- Accuracy:\", round(conf_matrix_train$overall[\"Accuracy\"], 4), \"\\n\")\n",
    "cat(\"- Log loss:\", round(logloss_value_train, 4), \"(lower is better)\\n\")\n",
    "cat(\"- Confusion Matrix:\\n\")\n",
    "print(conf_matrix_train$table)\n",
    "\n",
    "# Afficher le nombre de noeuds et de feuilles en français\n",
    "cat(\"Nombre de noeuds dans l'arbre : \", length(tree.reg.exp$frame$var), \"\\n\")\n",
    "cat(\"Nombre de feuilles dans l'arbre : \", length(tree.reg.exp$frame$var[tree.reg.exp$frame$var == \"<leaf>\"]), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :**\n",
    "\n",
    "L'arbre de régression construit avec un paramètre de complexité faible (`cp = 0.0001`) montre des performances solides mais indique un potentiel sur-apprentissage.\n",
    "\n",
    "**Performance sur le jeu de test :**\n",
    "- **Précision :** 87,11 % - Bonne capacité à classer correctement les observations.\n",
    "- **Log loss :** 0.2528 - Indique des prédictions probabilistes bien calibrées.\n",
    "- **Matrice de confusion :** Bonne distinction des classes, mais quelques confusions entre les classes 1 et 2.\n",
    "\n",
    "**Performance sur le jeu d'entraînement :**\n",
    "- **Précision :** 94,74 % - Ajustement presque parfait aux données d'entraînement.\n",
    "- **Log loss :** 0.1257 - Confirme un ajustement très précis.\n",
    "\n",
    "**Conclusion :**\n",
    "L'écart entre les performances d'entraînement et de test (94,74 % vs 87,11 %) et les log loss (0.1257 vs 0.2528) suggère un sur-apprentissage dû à une complexité excessive. Malgré cela, le modèle capture bien les relations dans les données. Une optimisation du paramètre de complexité (`cp`) pourrait améliorer la généralisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sélection du paramètre de complexité (cp) par validation croisée**\n",
    "\n",
    "Pour éviter le sur-apprentissage et obtenir un arbre de régression optimal, il est important de choisir correctement le paramètre de complexité (`cp`). La méthode classique consiste à utiliser la validation croisée intégrée à l’algorithme `rpart` :\n",
    "\n",
    "- On ajuste d’abord un arbre avec une valeur de `cp` très faible, ce qui permet à l’arbre de se développer au maximum.\n",
    "- `rpart` réalise automatiquement une validation croisée (par défaut à 10 plis) et enregistre, pour différentes valeurs de `cp`, l’erreur de validation croisée associée.\n",
    "- On visualise ensuite l’évolution de l’erreur de validation croisée en fonction de `cp` à l’aide de la fonction `plotcp()`.\n",
    "- Le `cp` optimal est celui qui minimise l’erreur de validation croisée (`xerror`). On peut aussi appliquer la règle du 1-SE pour sélectionner un arbre plus simple si plusieurs valeurs de `cp` donnent des erreurs similaires.\n",
    "- Enfin, on élague l’arbre initial avec la valeur optimale de `cp` pour obtenir un modèle plus parcimonieux et mieux généralisant.\n",
    "\n",
    "Cette démarche permet de sélectionner automatiquement la complexité de l’arbre en fonction des performances sur des données non vues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Ajuster l'arbre avec un cp faible pour explorer toute la complexité\n",
    "tree.class.exp <- rpart(Experience_Level ~ ., data = gym_train, method = \"class\", control = rpart.control(cp = 0.0001))\n",
    "\n",
    "# Visualiser la courbe d'erreur de validation croisée\n",
    "plotcp(tree.class.exp)\n",
    "\n",
    "# Extraire la table des cp\n",
    "cp_table <- tree.class.exp$cptable\n",
    "\n",
    "# Trouver le cp optimal (celui qui minimise l'erreur de validation croisée)\n",
    "min_xerror_idx <- which.min(cp_table[,\"xerror\"])\n",
    "cp_optimal <- cp_table[min_xerror_idx, \"CP\"]\n",
    "cat(\"Le cp optimal est :\", cp_optimal, \"\\n\")\n",
    "\n",
    "# Élaguer l'arbre avec le cp optimal\n",
    "tree.class.exp.pruned <- prune(tree.class.exp, cp = cp_optimal)\n",
    "\n",
    "# Visualiser l'arbre élagué\n",
    "rpart.plot(tree.class.exp.pruned, extra = 104, type = 3, under = TRUE, cex = 0.8, tweak = 1)\n",
    "\n",
    "# Prédictions sur le jeu de test\n",
    "pred_classes_test <- predict(tree.class.exp.pruned, gym_test, type = \"class\")\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix_test <- confusionMatrix(pred_classes_test, gym_test$Experience_Level)\n",
    "\n",
    "# Afficher le nombre de noeuds et de feuilles\n",
    "cat(\"Nombre de noeuds dans l'arbre elague :\", length(tree.class.exp.pruned$frame$var), \"\\n\")\n",
    "cat(\"Nombre de feuilles dans l'arbre elague :\", length(tree.class.exp$frame$var[tree.class.exp$frame$var == \"<leaf>\"]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prédictions sur le jeu de test (classes et probabilités)\n",
    "pred_classes_test <- predict(tree.class.exp.pruned, gym_test, type = \"class\")\n",
    "pred_probs_test <- predict(tree.class.exp.pruned, gym_test, type = \"prob\")\n",
    "\n",
    "# Prédictions sur le jeu d'entraînement (classes et probabilités)\n",
    "pred_classes_train <- predict(tree.class.exp.pruned, gym_train, type = \"class\")\n",
    "pred_probs_train <- predict(tree.class.exp.pruned, gym_train, type = \"prob\")\n",
    "\n",
    "# Matrices de confusion\n",
    "conf_matrix_test <- confusionMatrix(pred_classes_test, gym_test$Experience_Level)\n",
    "conf_matrix_train <- confusionMatrix(pred_classes_train, gym_train$Experience_Level)\n",
    "\n",
    "# Log loss (nécessite MLmetrics)\n",
    "actual_matrix_test <- model.matrix(~gym_test$Experience_Level-1)\n",
    "actual_matrix_train <- model.matrix(~gym_train$Experience_Level-1)\n",
    "logloss_test <- MultiLogLoss(y_pred = pred_probs_test, y_true = actual_matrix_test)\n",
    "logloss_train <- MultiLogLoss(y_pred = pred_probs_train, y_true = actual_matrix_train)\n",
    "\n",
    "# Affichage des résultats\n",
    "cat(\"Test Set Performance:\\n\")\n",
    "cat(\"- Accuracy:\", round(conf_matrix_test$overall[\"Accuracy\"], 4), \"\\n\")\n",
    "cat(\"- Log loss:\", round(logloss_test, 4), \"(lower is better)\\n\")\n",
    "cat(\"- Confusion Matrix:\\n\")\n",
    "print(conf_matrix_test$table)\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"Training Set Performance:\\n\")\n",
    "cat(\"- Accuracy:\", round(conf_matrix_train$overall[\"Accuracy\"], 4), \"\\n\")\n",
    "cat(\"- Log loss:\", round(logloss_train, 4), \"(lower is better)\\n\")\n",
    "cat(\"- Confusion Matrix:\\n\")\n",
    "print(conf_matrix_train$table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complexité de l’arbre avant et après élagage\n",
    "\n",
    "- **Premier arbre (cp très faible, arbre complexe) :**\n",
    "  - Nombre de nœuds dans l’arbre : **37**\n",
    "  - Nombre de feuilles dans l’arbre : **19**\n",
    "\n",
    "  Cet arbre très développé s’ajuste fortement aux données d’entraînement, ce qui favorise le sur-apprentissage.\n",
    "\n",
    "- **Arbre élagué (cp optimal) :**\n",
    "  - Nombre de nœuds dans l’arbre élagué : **9**\n",
    "  - Nombre de feuilles dans l’arbre élagué : **19**\n",
    "\n",
    "  Après élagage, l’arbre conserve le même nombre de feuilles (donc la même capacité de séparation des classes), mais avec beaucoup moins de nœuds internes. Cela signifie que la structure de l’arbre est simplifiée, ce qui améliore la robustesse et la capacité de généralisation du modèle.\n",
    "\n",
    "#### Résultats avant et après élagage\n",
    "\n",
    "**Avant élagage (cp très faible, arbre complexe)**\n",
    "\n",
    "- **Jeu de test :**\n",
    "  - Accuracy : 0.8711\n",
    "  - Log loss : 0.2528\n",
    "  - L’arbre distingue bien les classes, mais il y a des confusions entre les classes 1 et 2.\n",
    "\n",
    "- **Jeu d’entraînement :**\n",
    "  - Accuracy : 0.9474\n",
    "  - Log loss : 0.1257\n",
    "  - Très bonne performance, mais l’écart avec le test montre un sur-apprentissage.\n",
    "\n",
    "---\n",
    "\n",
    "**Après élagage (cp optimal = 0.0044, arbre plus simple)**\n",
    "\n",
    "- **Jeu de test :**\n",
    "  - Accuracy : 0.9021 (en hausse)\n",
    "  - Log loss : 0.1977 (en baisse, donc meilleur)\n",
    "  - La matrice de confusion montre moins d’erreurs, surtout pour la classe 2.\n",
    "\n",
    "- **Jeu d’entraînement :**\n",
    "  - Accuracy : 0.9037 (en baisse, mais plus proche du test)\n",
    "  - Log loss : 0.1817 (en légère hausse, mais toujours bonne)\n",
    "  - Les performances sont désormais très proches entre entraînement et test.\n",
    "\n",
    "---\n",
    "\n",
    "**Interprétation**\n",
    "\n",
    "L’élagage avec le cp optimal a permis de réduire le sur-apprentissage : l’écart entre les performances d’entraînement et de test a diminué.  \n",
    "Le modèle généralise mieux : la précision sur le test augmente, la log loss diminue.  \n",
    "L’arbre est plus simple et plus robuste : il fait moins d’erreurs sur des données non vues, même si la précision d’entraînement baisse un peu (ce qui est normal et souhaité).\n",
    "\n",
    "**Conclusion :**  \n",
    "L’utilisation du cp optimal améliore la capacité de généralisation du modèle, en évitant qu’il ne s’ajuste trop aux particularités du jeu d’entraînement. C’est exactement l’objectif de la validation croisée et de l’élagage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests and Boosting\n",
    "- Random forests with `mtry` and Brieman criterion\n",
    "- Regularization with Boosting\n",
    "- Using Bootstrap\n",
    "- **plot** feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement du modèle Random Forest\n",
    "\n",
    "L'objectif des forets aléatoires est de réduire la variance des arbres tout en conservant leur pouvoir prédictif via le bagging, qui est une technique combinant bootstraping et agrégation d'arbres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "# Entraînement du modèle Random Forest\n",
    "rf_model <- randomForest(Experience_Level ~ ., \n",
    "                         data = gym_train,\n",
    "                         ntree = 500,           # nombre d’arbres\n",
    "                         mtry = 4,              # nombre de variables testées à chaque split\n",
    "                         importance = TRUE)     # permet de calculer l’importance des variables\n",
    "\n",
    "# Résumé du modèle\n",
    "print(rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation du modèle Random Forest\n",
    "\n",
    "Le modèle Random Forest a été entraîné pour prédire la variable **Experience_Level** à partir des données d’entraînement.\n",
    "\n",
    "- **Nombre d’arbres :** 500\n",
    "- **Variables testées à chaque split (mtry) :** 4\n",
    "\n",
    "#### Résultats sur le jeu d’entraînement (OOB)\n",
    "\n",
    "- **Taux d’erreur OOB (Out-Of-Bag) :** 10,53 %\n",
    "  - Cela signifie que le modèle se trompe en moyenne sur 10,53 % des observations non vues lors de la construction de chaque arbre.\n",
    "- **Matrice de confusion :**\n",
    "  - **Classe 1 :** 230 bien classés, 71 mal classés (erreur : 23,6 %)\n",
    "  - **Classe 2 :** 314 bien classés, 11 mal classés (erreur : 3,4 %)\n",
    "  - **Classe 3 :** 153 bien classés, 0 mal classés (erreur : 0 %)\n",
    "\n",
    "#### Interprétation\n",
    "\n",
    "- Le modèle distingue très bien la classe 3 (aucune erreur) et la classe 2 (faible taux d’erreur).\n",
    "- Il a plus de difficultés à bien prédire la classe 1 (23,6 % d’erreur).\n",
    "- Le taux d’erreur global est faible, ce qui indique une bonne capacité de classification sur les données d’entraînement.\n",
    "- L’utilisation de 500 arbres et la sélection aléatoire de variables à chaque split permettent de limiter le sur-apprentissage et d’améliorer la robustesse du modèle.\n",
    "\n",
    "Intéressons-nous maintenant à l'évaluation de notre modèle sur nos jeux d'entraînement et de test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prédictions Random Forest sur le jeu de test (classes et probabilités)\n",
    "pred_classes_test_rf <- predict(rf_model, gym_test, type = \"class\")\n",
    "pred_probs_test_rf <- predict(rf_model, gym_test, type = \"prob\")\n",
    "\n",
    "# Prédictions sur le jeu d'entraînement\n",
    "pred_classes_train_rf <- predict(rf_model, gym_train, type = \"class\")\n",
    "pred_probs_train_rf <- predict(rf_model, gym_train, type = \"prob\")\n",
    "\n",
    "# Matrices de confusion\n",
    "conf_matrix_test_rf <- confusionMatrix(pred_classes_test_rf, gym_test$Experience_Level)\n",
    "conf_matrix_train_rf <- confusionMatrix(pred_classes_train_rf, gym_train$Experience_Level)\n",
    "\n",
    "# Log loss (nécessite MLmetrics)\n",
    "actual_matrix_test_rf <- model.matrix(~gym_test$Experience_Level-1)\n",
    "actual_matrix_train_rf <- model.matrix(~gym_train$Experience_Level-1)\n",
    "logloss_test_rf <- MultiLogLoss(y_pred = pred_probs_test_rf, y_true = actual_matrix_test_rf)\n",
    "logloss_train_rf <- MultiLogLoss(y_pred = pred_probs_train_rf, y_true = actual_matrix_train_rf)\n",
    "\n",
    "# Affichage des résultats\n",
    "cat(\"Test Set Performance (Random Forest):\\n\")\n",
    "cat(\"- Accuracy:\", round(conf_matrix_test_rf$overall[\"Accuracy\"], 4), \"\\n\")\n",
    "cat(\"- Log loss:\", round(logloss_test_rf, 4), \"(lower is better)\\n\")\n",
    "cat(\"- Confusion Matrix:\\n\")\n",
    "print(conf_matrix_test_rf$table)\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"Training Set Performance (Random Forest):\\n\")\n",
    "cat(\"- Accuracy:\", round(conf_matrix_train_rf$overall[\"Accuracy\"], 4), \"\\n\")\n",
    "cat(\"- Log loss:\", round(logloss_train_rf, 4), \"(lower is better)\\n\")\n",
    "cat(\"- Confusion Matrix:\\n\")\n",
    "print(conf_matrix_train_rf$table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Interprétation des performances sur le jeu d'entraînement\n",
    "\n",
    "Le modèle Random Forest affiche une précision (accuracy) de **100%** sur le jeu d'entraînement, ce qui signifie qu’il a correctement classé **l’intégralité des observations** de cet échantillon. Bien que ce résultat puisse sembler excellent, il doit être interprété avec prudence. En effet, cette absence totale d’erreurs sur les données d'entraînement est généralement le signe d’un **surapprentissage** (*overfitting*), c’est-à-dire que le modèle a appris **par cœur les données** plutôt que de généraliser les tendances sous-jacentes.\n",
    "\n",
    "Ce phénomène est confirmé par la comparaison avec l’estimation de l’erreur **OOB (Out-Of-Bag)**, fournie par le modèle pendant l'entraînement, qui était d’environ **10,78%**. Cette erreur OOB est considérée comme une estimation plus fiable de la performance réelle, car elle est calculée à partir d'observations non utilisées pour construire chaque arbre.\n",
    "\n",
    "Ainsi, bien que l’accuracy de 100% témoigne d’une forte capacité du modèle à mémoriser les données, elle ne garantit pas une bonne capacité de généralisation. L’évaluation sur un jeu de test indépendant reste indispensable pour valider les performances du modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif des forêts aléatoires est de réduire la **variance des arbres de décision** tout en conservant leur pouvoir prédictif. Elles reposent sur la technique du **bagging**, qui combine **bootstraping** (tirages aléatoires avec remise) et **agrégation de prédictions** (par vote majoritaire dans le cas de la classification).\n",
    "\n",
    "Contrairement à un arbre classique, à chaque nœud d’un arbre de la forêt, **un sous-ensemble aléatoire de variables est sélectionné** (de taille `mtry`), et la **meilleure variable parmi ce sous-ensemble** est utilisée pour réaliser la division. Ce mécanisme permet de **décorréler les arbres entre eux**, ce qui renforce la robustesse globale du modèle.\n",
    "\n",
    "### Paramètres à optimiser :\n",
    "\n",
    "- **`mtry`** : nombre de variables sélectionnées aléatoirement à chaque split.\n",
    "    - Dans le cas de la **classification**, la valeur empirique par défaut est `mtry ≈ √p`, où `p` est le nombre total de variables explicatives. Ici, `p = 14`, donc `mtry` vaut par défaut `√p = √14 = 4`.\n",
    "    - L’optimisation de `mtry` est réalisée via la fonction `tuneRF`, qui cherche le meilleur compromis entre complexité et performance. Cette fonction commence à une valeur initiale (`mtry = 4` ici) et teste des valeurs supérieures et inférieures tant que l’erreur de généralisation mesurée par le taux d’erreur **OOB (Out-Of-Bag)** s’améliore d’au moins 5% (ce seuil est modifiable).\n",
    "\n",
    "- **`ntree`** : nombre d’arbres dans la forêt.\n",
    "    - En général, `ntree` varie de 100 à 500. Au-delà, les gains de performance sont marginaux, mais cela peut améliorer la **stabilité** de la prédiction. Dans ce projet, nous utilisons `ntree = 500` pour garantir la convergence des résultats.\n",
    "\n",
    "Cette combinaison d’aléatoire (dans les données et dans les variables) permet à Random Forest d’offrir un excellent compromis entre **performance** et **généralisation**, même sans réglage excessif d’hyperparamètres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimisation du `mtry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "\n",
    "# Optimisation du mtry avec tuneRF\n",
    "best_mtry <- tuneRF(x = gym_train[ , -which(names(gym_train) == \"Experience_Level\")],\n",
    "                    y = gym_train$Experience_Level,\n",
    "                    stepFactor = 1.5,\n",
    "                    improve = 0.05,\n",
    "                    ntreeTry = 100,\n",
    "                    trace = TRUE,\n",
    "                    plot = TRUE,\n",
    "                    doBest = TRUE)\n",
    "\n",
    "optimal_mtry <- best_mtry$mtry\n",
    "cat(\"Optimal mtry value:\", optimal_mtry, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre `mtry` a été optimisé automatiquement à l'aide de la fonction `tuneRF()`, qui teste différentes valeurs de `mtry` autour d'une valeur initiale (ici, `√p = 4`), en les multipliant ou divisant par un facteur `stepFactor = 1.5`. L'évaluation de chaque `mtry` est réalisée à l'aide de 100 arbres (`ntreeTry = 100`) afin d'obtenir une estimation rapide mais fiable de l'erreur OOB. \n",
    "\n",
    "Le processus de tuning s'arrête dès qu'aucune amélioration significative (au moins `5%`) de l'erreur OOB n’est observée (`improve = 0.05`). L’option `doBest = TRUE` permet enfin de réentraîner automatiquement un modèle avec la meilleure valeur trouvée, ce qui facilite l'intégration du tuning dans le workflow.\n",
    "\n",
    "Cette procédure a confirmé que `mtry = 4` (valeur théorique par défaut pour la classification avec 14 variables explicatives) offrait les meilleures performances, sans amélioration notable au-delà.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prédictions Random Forest optimisé (best_mtry) sur test et train\n",
    "pred_classes_test_best <- predict(best_mtry, gym_test, type = \"class\")\n",
    "pred_probs_test_best <- predict(best_mtry, gym_test, type = \"prob\")\n",
    "\n",
    "pred_classes_train_best <- predict(best_mtry, gym_train, type = \"class\")\n",
    "pred_probs_train_best <- predict(best_mtry, gym_train, type = \"prob\")\n",
    "\n",
    "# Matrices de confusion\n",
    "conf_matrix_test_best <- confusionMatrix(pred_classes_test_best, gym_test$Experience_Level)\n",
    "conf_matrix_train_best <- confusionMatrix(pred_classes_train_best, gym_train$Experience_Level)\n",
    "\n",
    "# Log loss (MultiLogLoss)\n",
    "actual_matrix_test_best <- model.matrix(~gym_test$Experience_Level-1)\n",
    "actual_matrix_train_best <- model.matrix(~gym_train$Experience_Level-1)\n",
    "logloss_test_best <- MultiLogLoss(y_pred = pred_probs_test_best, y_true = actual_matrix_test_best)\n",
    "logloss_train_best <- MultiLogLoss(y_pred = pred_probs_train_best, y_true = actual_matrix_train_best)\n",
    "\n",
    "# Affichage des résultats\n",
    "cat(\"Test Set Performance (Random Forest optimisé):\\n\")\n",
    "cat(\"- Accuracy:\", round(conf_matrix_test_best$overall[\"Accuracy\"], 4), \"\\n\")\n",
    "cat(\"- Log loss:\", round(logloss_test_best, 4), \"(lower is better)\\n\")\n",
    "cat(\"- Confusion Matrix:\\n\")\n",
    "print(conf_matrix_test_best$table)\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"Training Set Performance (Random Forest optimisé):\\n\")\n",
    "cat(\"- Accuracy:\", round(conf_matrix_train_best$overall[\"Accuracy\"], 4), \"\\n\")\n",
    "cat(\"- Log loss:\", round(logloss_train_best, 4), \"(lower is better)\\n\")\n",
    "cat(\"- Confusion Matrix:\\n\")\n",
    "print(conf_matrix_train_best$table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Importance des variables\n",
    "library(ggRandomForests)\n",
    "\n",
    "#Plot importance\n",
    "varImpPlot(rf_model, main = \"Importance des variables (Random Forest)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'importance des variables a été évaluée à l’aide des mesures intégrées à l’algorithme Random Forest. Deux métriques complémentaires ont été analysées :\n",
    "\n",
    "- **Mean Decrease in Accuracy** : elle mesure la perte de précision du modèle lorsque les valeurs d’une variable sont aléatoirement permutées. Cette mesure est considérée comme la plus fiable car elle reflète directement l’impact de la variable sur la performance globale du modèle.\n",
    "- **Mean Decrease in Gini** : elle correspond à la réduction moyenne de l’impureté des nœuds (indice de Gini) induite par l’utilisation d’une variable pour diviser les données dans les arbres. Bien qu’efficace, cette métrique peut être biaisée en faveur des variables numériques continues.\n",
    "\n",
    "Le graphique montre que des variables telles que `Session_Duration..hours.`, `Workout_Frequency` ou encore `Fat_Percentage` sont parmi les plus influentes dans la prédiction du niveau d’expérience. Ces résultats sont cohérents avec l’analyse exploratoire, qui avait déjà mis en évidence des corrélations fortes entre ces variables et la variable cible `Experience_Level`.\n",
    "\n",
    "Cette observation est tout à fait cohérente : les profils les plus expérimentés sont aussi ceux qui cumulent une fréquence d'entraînement élevée, un volume d’exercice important et un taux de masse grasse plus bas, autant d’indicateurs caractéristiques d’une pratique sportive régulière et avancée.\n",
    "\n",
    "L’analyse de l’importance des variables permet non seulement d’interpréter le modèle, mais aussi d’identifier les facteurs les plus déterminants dans la progression des adhérents d'une salle de sport.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting\n",
    "##### Avec la librairie `xgboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Entraînement d'un premier modèle baseline\n",
    "\n",
    "Nous avons d'abord construit un modèle de base en spécifiant les paramètres suivants :\n",
    "- `objective = \"multi:softprob\"` : configuration adaptée à une classification multi-classes, permettant d'obtenir les probabilités associées à chaque classe.\n",
    "- `num_class = 3` : car la variable cible comporte trois niveaux.\n",
    "- `eval_metric = \"mlogloss\"` : la fonction de perte choisie est le log loss, adaptée aux probabilités.\n",
    "- `eta = 0.1` : taux d'apprentissage modéré pour stabiliser l'entraînement.\n",
    "- `max_depth = 6` : profondeur maximale des arbres.\n",
    "- `subsample = 0.8` et `colsample_bytree = 0.8` : échantillonnage partiel des données et des variables pour limiter le surapprentissage.\n",
    "\n",
    "Ce modèle initial a été entraîné avec 300 arbres (`nrounds = 300`).  \n",
    "Les prédictions ont ensuite été obtenues sous forme de probabilités pour chaque classe.  \n",
    "La classe prédite correspond à celle ayant la probabilité la plus élevée.\n",
    "\n",
    "Une évaluation préliminaire par **matrice de confusion** sur le jeu de test a permis d'obtenir une **accuracy de 85.57%**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(xgboost)\n",
    "library(caret)\n",
    "\n",
    "# Créer les matrices d'entraînement\n",
    "X_train <- model.matrix(Experience_Level ~ . -1, data = gym_train)\n",
    "y_train <- as.numeric(gym_train$Experience_Level) - 1  # XGBoost demande des labels 0, 1, 2\n",
    "\n",
    "X_test <- model.matrix(Experience_Level ~ . -1, data = gym_test)\n",
    "y_test <- as.numeric(gym_test$Experience_Level) - 1\n",
    "\n",
    "# Transformer en objets DMatrix pour XGBoost\n",
    "dtrain <- xgb.DMatrix(data = X_train, label = y_train)\n",
    "dtest <- xgb.DMatrix(data = X_test, label = y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Définir les paramètres\n",
    "params <- list(\n",
    "  objective = \"multi:softprob\",   # pour multi-classes avec probabilités\n",
    "  num_class = 3,                  # 3 classes ici\n",
    "  eval_metric = \"mlogloss\"         # log loss pour la stabilité\n",
    ")\n",
    "\n",
    "# Entraîner\n",
    "set.seed(24)\n",
    "xgb_model <- xgb.train(\n",
    "  params = params,\n",
    "  data = dtrain,\n",
    "  nrounds = 300,          # 300 arbres\n",
    "  eta = 0.1,              # learning rate correct\n",
    "  max_depth = 6,          # arbres raisonnablement profonds\n",
    "  subsample = 0.8,        # sous-échantillonnage pour éviter overfitting\n",
    "  colsample_bytree = 0.8, # sous-échantillonnage des colonnes\n",
    "  verbose = 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prédictions : probabilités\n",
    "pred_probs <- predict(xgb_model, newdata = dtest)\n",
    "\n",
    "# Reformater en matrice : chaque ligne correspond à un individu\n",
    "pred_matrix <- matrix(pred_probs, ncol = 3, byrow = TRUE)\n",
    "\n",
    "# Prendre la classe la plus probable\n",
    "pred_classes <- max.col(pred_matrix) - 1  # car max.col commence à 1\n",
    "\n",
    "# Comparer aux vraies classes\n",
    "confusionMatrix(as.factor(pred_classes), as.factor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Optimisation des hyperparamètres par validation croisée\n",
    "\n",
    "Afin d'améliorer ce modèle, nous avons mis en place une **recherche sur grille (grid search)** couplée à une **validation croisée 5 folds**.  \n",
    "La grille explorait les paramètres suivants :\n",
    "- `nrounds` : 300 et 500\n",
    "- `max_depth` : 4, 6, 8\n",
    "- `eta` : 0.05 et 0.1\n",
    "- `gamma` : 0 et 1\n",
    "- `colsample_bytree` : 0.7 et 1\n",
    "- `min_child_weight` : 1 et 5\n",
    "- `subsample` : 0.7 et 1\n",
    "\n",
    "Le critère d'optimisation était la **précision (`Accuracy`)** sur les données de validation.\n",
    "\n",
    "Cette recherche a permis d'identifier la meilleure combinaison d'hyperparamètres.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Grille d'hyperparamètres à explorer\n",
    "grid <- expand.grid(\n",
    "  nrounds = c(300, 500),\n",
    "  max_depth = c(4, 6, 8),\n",
    "  eta = c(0.05, 0.1),\n",
    "  gamma = c(0, 1),\n",
    "  colsample_bytree = c(0.7, 1),\n",
    "  min_child_weight = c(1, 5),\n",
    "  subsample = c(0.7, 1)\n",
    ")\n",
    "\n",
    "# 5-fold CV\n",
    "ctrl <- trainControl(\n",
    "  method = \"cv\",\n",
    "  number = 5,\n",
    "  verboseIter = TRUE,\n",
    "  allowParallel = TRUE\n",
    ")\n",
    "\n",
    "set.seed(24)\n",
    "xgb_tuned_full <- train(\n",
    "  Experience_Level ~ .,\n",
    "  data = gym_train, # Utiliser gym_train au lieu de train_data\n",
    "  method = \"xgbTree\",\n",
    "  trControl = ctrl,\n",
    "  tuneGrid = grid,\n",
    "  metric = \"Accuracy\",\n",
    "  verbose = 0 # Mettre à 1 ou TRUE pour voir la progression si désiré\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3. Entraînement du modèle final\n",
    "\n",
    "Un modèle final a ensuite été réentraîné sur l'intégralité du jeu `gym_train` en utilisant les hyperparamètres optimaux trouvés.  \n",
    "Ce modèle utilise :\n",
    "- Le meilleur `nrounds`\n",
    "- Le meilleur `max_depth`\n",
    "- Le meilleur `eta`, `gamma`, `subsample`, `colsample_bytree`, `min_child_weight`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extraire les meilleurs paramètres trouvés\n",
    "best_params <- xgb_tuned_full$bestTune\n",
    "\n",
    "# Créer une matrice DMatrix pour tout gym_train\n",
    "dtrain <- xgb.DMatrix(data = X_train, label = y_train)\n",
    "\n",
    "# Réentraîner avec les meilleurs hyperparamètres\n",
    "set.seed(24)\n",
    "xgb_final_model <- xgboost(\n",
    "  data = dtrain,\n",
    "  objective = \"multi:softprob\",\n",
    "  num_class = 3,\n",
    "  eval_metric = \"mlogloss\",\n",
    "  nrounds = best_params$nrounds,\n",
    "  max_depth = best_params$max_depth,\n",
    "  eta = best_params$eta,\n",
    "  gamma = best_params$gamma,\n",
    "  colsample_bytree = best_params$colsample_bytree,\n",
    "  min_child_weight = best_params$min_child_weight,\n",
    "  subsample = best_params$subsample,\n",
    "  verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Évaluation finale\n",
    "\n",
    "Les prédictions finales sur le jeu de test `gym_test` ont été réalisées en prenant la classe associée à la probabilité la plus élevée.\n",
    "\n",
    "L'évaluation par **matrice de confusion** a permis d'obtenir une **accuracy finale** (précision) correspondant à la performance maximale atteinte par le modèle optimisé.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prédictions finales XGBoost sur le jeu de test (probabilités)\n",
    "pred_probs_final <- predict(xgb_final_model, newdata = dtest)\n",
    "pred_matrix_final <- matrix(pred_probs_final, ncol = 3, byrow = TRUE)\n",
    "\n",
    "# Classe prédite = colonne avec la probabilité max (commence à 1)\n",
    "pred_classes_final <- max.col(pred_matrix_final)\n",
    "# Adapter les niveaux pour correspondre à gym_test$Experience_Level\n",
    "pred_classes_final_factor <- factor(pred_classes_final, levels = 1:3, labels = levels(gym_test$Experience_Level))\n",
    "\n",
    "# Calcul MultiLogLoss pour le test\n",
    "actual_matrix_test_xgb <- model.matrix(~gym_test$Experience_Level-1)\n",
    "logloss_test_xgb <- MultiLogLoss(y_pred = pred_matrix_final, y_true = actual_matrix_test_xgb)\n",
    "\n",
    "# Accuracy et matrice de confusion (test)\n",
    "conf_matrix_test_xgb <- confusionMatrix(pred_classes_final_factor, gym_test$Experience_Level)\n",
    "accuracy_test_xgb <- conf_matrix_test_xgb$overall[\"Accuracy\"]\n",
    "\n",
    "# Prédictions sur le jeu d'entraînement (probabilités)\n",
    "pred_probs_train_final <- predict(xgb_final_model, newdata = dtrain)\n",
    "pred_matrix_train_final <- matrix(pred_probs_train_final, ncol = 3, byrow = TRUE)\n",
    "pred_classes_train_final <- max.col(pred_matrix_train_final)\n",
    "pred_classes_train_final_factor <- factor(pred_classes_train_final, levels = 1:3, labels = levels(gym_train$Experience_Level))\n",
    "\n",
    "actual_matrix_train_xgb <- model.matrix(~gym_train$Experience_Level-1)\n",
    "logloss_train_xgb <- MultiLogLoss(y_pred = pred_matrix_train_final, y_true = actual_matrix_train_xgb)\n",
    "\n",
    "# Accuracy et matrice de confusion (train)\n",
    "conf_matrix_train_xgb <- confusionMatrix(pred_classes_train_final_factor, gym_train$Experience_Level)\n",
    "accuracy_train_xgb <- conf_matrix_train_xgb$overall[\"Accuracy\"]\n",
    "\n",
    "# Affichage des résultats\n",
    "cat(\"MultiLogLoss XGBoost (test):\", round(logloss_test_xgb, 4), \"\\n\")\n",
    "cat(\"Accuracy XGBoost (test):\", round(accuracy_test_xgb, 4), \"\\n\")\n",
    "cat(\"Matrice de confusion (test):\\n\")\n",
    "print(conf_matrix_test_xgb$table)\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"MultiLogLoss XGBoost (train):\", round(logloss_train_xgb, 4), \"\\n\")\n",
    "cat(\"Accuracy XGBoost (train):\", round(accuracy_train_xgb, 4), \"\\n\")\n",
    "cat(\"Matrice de confusion (train):\\n\")\n",
    "print(conf_matrix_train_xgb$table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Comparaison des performances des modèles\n",
    "\n",
    "| Modèle         | Accuracy | Log Loss |\n",
    "|----------------|----------|----------|\n",
    "| CART           | 0.902    | 0.198    |\n",
    "| Random Forest  | 0.892    | 0.246    |\n",
    "| XGBoost        | 0.881    | 0.224    |\n",
    "\n",
    "### Synthèse finale : Comparaison de CART, Random Forest et XGBoost\n",
    "\n",
    "Trois modèles d'apprentissage supervisé ont été comparés pour prédire le niveau d'expérience (`Experience_Level`) :\n",
    "\n",
    "- **CART** (Classification and Regression Trees) affiche la meilleure performance globale, avec une **accuracy** de ~90,2% et la **log loss** la plus faible (0.198). Cela indique non seulement une bonne capacité de classification, mais aussi des probabilités de prédiction bien calibrées.\n",
    "  \n",
    "- **Random Forest** obtient une accuracy de ~89,2% et une log loss de 0.246. Le modèle reste robuste et performant, mais ses probabilités sont un peu moins précises que celles du CART, comme l'indique la log loss plus élevée.\n",
    "\n",
    "- **XGBoost** atteint une accuracy de ~88,1% et une log loss de 0.224. Malgré un tuning approfondi, il reste légèrement en retrait sur ce jeu de données, mais ses probabilités sont mieux calibrées que celles du Random Forest.\n",
    "\n",
    "En conclusion, bien que Random Forest et XGBoost soient réputés pour leur puissance en modélisation avancée, le modèle CART, plus simple, s'est révélé le plus adapté à ce jeu de données, combinant **performance élevée**, **interprétabilité** et **prédictions probabilistes fiables** (log loss minimale).  \n",
    "Le choix final du modèle dépendra donc du compromis souhaité entre performance pure, qualité des probabilités et simplicité d'interprétation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure pROC is loaded (if not already)\n",
    "# library(pROC)\n",
    "\n",
    "# Ensure Experience_Level is a factor\n",
    "gym_test$Experience_Level <- as.factor(gym_test$Experience_Level)\n",
    "class_levels <- levels(gym_test$Experience_Level)\n",
    "\n",
    "# Define colors for each model (CART, Random Forest, XGBoost)\n",
    "model_colors <- c(\"blue\", \"red\", \"green\") \n",
    "model_names <- c(\"CART\", \"Random Forest\", \"XGBoost\")\n",
    "\n",
    "# Loop through each class to create a separate plot\n",
    "for (i in 1:length(class_levels)) {\n",
    "  current_class <- class_levels[i]\n",
    "  \n",
    "  legend_labels_for_class <- c()\n",
    "  \n",
    "  # Create binary response: 1 if current_class, 0 otherwise\n",
    "  # This response is the same for all models for this specific class\n",
    "  response_binary <- ifelse(gym_test$Experience_Level == current_class, 1, 0)\n",
    "  \n",
    "  # 1. CART Model\n",
    "  # Probabilities for the current class from CART predictions\n",
    "  # Assuming pred_probs_test columns are ordered according to class_levels\n",
    "  prob_cart_current_class <- pred_probs_test[, i]\n",
    "  roc_obj_cart <- roc(response = response_binary, predictor = prob_cart_current_class, quiet = TRUE)\n",
    "  \n",
    "  # Plot ROC curve for CART (this will be the first curve on the new plot)\n",
    "  # Add title directly to the plot call\n",
    "  plot(roc_obj_cart, col = model_colors[1], legacy.axes = TRUE, print.auc = FALSE,\n",
    "       main = paste(\"ROC Curves for Class '\", current_class, \"' vs Rest\", sep=\"\"),\n",
    "       sub = \"Comparison of CART, Random Forest, and XGBoost\")\n",
    "  legend_labels_for_class <- c(legend_labels_for_class, \n",
    "                               paste(model_names[1], \" (AUC = \", round(auc(roc_obj_cart), 3), \")\", sep=\"\"))\n",
    "  \n",
    "  # 2. Random Forest Model\n",
    "  # Probabilities for the current class from Random Forest predictions\n",
    "  # Assuming pred_probs_test_rf columns are ordered according to class_levels\n",
    "  prob_rf_current_class <- pred_probs_test_rf[, i]\n",
    "  roc_obj_rf <- roc(response = response_binary, predictor = prob_rf_current_class, quiet = TRUE)\n",
    "  \n",
    "  # Plot ROC curve for Random Forest (add to the existing plot)\n",
    "  plot(roc_obj_rf, col = model_colors[2], add = TRUE, print.auc = FALSE)\n",
    "  legend_labels_for_class <- c(legend_labels_for_class, \n",
    "                               paste(model_names[2], \" (AUC = \", round(auc(roc_obj_rf), 3), \")\", sep=\"\"))\n",
    "  \n",
    "  # 3. XGBoost Model\n",
    "  # Probabilities for the current class from XGBoost predictions\n",
    "  # Assuming pred_matrix_final columns are ordered according to class_levels\n",
    "  # (e.g., col 1 for class_levels[1], col 2 for class_levels[2], etc.)\n",
    "  prob_xgb_current_class <- pred_matrix_final[, i] \n",
    "  roc_obj_xgb <- roc(response = response_binary, predictor = prob_xgb_current_class, quiet = TRUE)\n",
    "  \n",
    "  # Plot ROC curve for XGBoost (add to the existing plot)\n",
    "  plot(roc_obj_xgb, col = model_colors[3], add = TRUE, print.auc = FALSE)\n",
    "  legend_labels_for_class <- c(legend_labels_for_class, \n",
    "                               paste(model_names[3], \" (AUC = \", round(auc(roc_obj_xgb), 3), \")\", sep=\"\"))\n",
    "  \n",
    "  # Add legend to the current plot\n",
    "  legend(\"bottomright\", legend = legend_labels_for_class, col = model_colors, lwd = 2, cex = 0.8)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des courbes ROC pour les classes 1, 2 et 3\n",
    "\n",
    "### Classe 1\n",
    "- **AUC (CART = 0.954, Random Forest = 0.941, XGBoost = 0.946)** :\n",
    "  - Le modèle **CART** est légèrement supérieur à **XGBoost** et **Random Forest** pour la classe `1`.\n",
    "  - Les trois modèles montrent une bonne capacité de discrimination pour cette classe, avec des AUC proches de 1.\n",
    "- **Conclusion** : CART est le modèle le plus performant pour la classe `1`, suivi de près par XGBoost.\n",
    "\n",
    "---\n",
    "\n",
    "### Classe 2\n",
    "- **AUC (CART = 0.955, Random Forest = 0.943, XGBoost = 0.948)** :\n",
    "  - CART reste légèrement meilleur que XGBoost et Random Forest pour la classe `2`.\n",
    "  - Les performances des trois modèles sont similaires, avec des AUC très proches.\n",
    "- **Conclusion** : CART est encore une fois le modèle le plus performant, mais XGBoost est presque équivalent.\n",
    "\n",
    "---\n",
    "\n",
    "### Classe 3\n",
    "- **AUC (CART = 1, Random Forest = 1, XGBoost = 1)** :\n",
    "  - Tous les modèles atteignent une AUC parfaite de `1` pour la classe `3`.\n",
    "  - Cela signifie que les trois modèles discriminent parfaitement la classe `3` des autres classes.\n",
    "- **Conclusion** : Les trois modèles sont équivalents pour la classe `3`.\n",
    "\n",
    "---\n",
    "\n",
    "### Synthèse globale\n",
    "1. **Classe 1 et Classe 2** :\n",
    "   - CART est légèrement meilleur que XGBoost et Random Forest pour ces classes, mais les différences sont minimes.\n",
    "   - Les trois modèles montrent une excellente capacité de discrimination avec des AUC supérieures à `0.94`.\n",
    "\n",
    "2. **Classe 3** :\n",
    "   - Tous les modèles atteignent une performance parfaite (AUC = 1), ce qui indique que cette classe est très bien séparée des autres.\n",
    "\n",
    "3. **Recommandation** :\n",
    "   - CART est globalement le modèle le plus performant pour ce problème, avec des AUC légèrement supérieures pour les classes `1` et `2`.\n",
    "   - XGBoost est une alternative compétitive, particulièrement pour des problèmes où une optimisation fine est nécessaire.\n",
    "   - Random Forest reste robuste et performant, mais légèrement en retrait par rapport aux deux autres modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
