{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "randomseed = 1234\n",
    "\n",
    "## DATA LOADING AND PREPROCESSING\n",
    "# Load the data\n",
    "gym = pd.read_csv('../../gym_members_exercise_tracking.csv')\n",
    "\n",
    "# set 'Gender', 'Workout_Type', 'Workout_Frequency (days/week)' and 'Experience_Level' as categorical\n",
    "for col in ['Gender', 'Workout_Type', 'Workout_Frequency (days/week)', 'Experience_Level']:\n",
    "    gym[col] = gym[col].astype('category')\n",
    "\n",
    "# log transform Weight and BMI\n",
    "gym['Weight (kg)'] = np.log1p(gym['Weight (kg)'])\n",
    "\n",
    "# transform 'Fat_Percentage'\n",
    "max_fat = gym['Fat_Percentage'].max()\n",
    "gym['Fat_Percentage'] = gym['Fat_Percentage'].apply(lambda x: np.sqrt(max_fat+1)-x)\n",
    "\n",
    "# rename transformed columns\n",
    "gym.rename(columns={'Weight (kg)': 'LWeight', 'Fat_Percentage': 'SFat_Percentage'}, inplace=True)\n",
    "\n",
    "gym.drop(columns=['BMI'], inplace=True)\n",
    "\n",
    "# divide into train and test set\n",
    "gym_train, gym_test = train_test_split(gym, test_size=0.2, random_state=randomseed)\n",
    "\n",
    "# Create gym_train_scale, gym_test_scale\n",
    "gym_train_scale = gym_train.copy()\n",
    "gym_test_scale = gym_test.copy()\n",
    "\n",
    "# Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "gym_train_scale[['LWeight', 'Height (m)', 'Max_BPM', 'Avg_BPM', 'Resting_BPM', 'Session_Duration (hours)',\n",
    "                             'Water_Intake (liters)', 'SFat_Percentage', 'Workout_Frequency (days/week)', 'Calories_Burned']] = scaler.fit_transform(gym_train_scale[['LWeight', 'Height (m)', 'Max_BPM', 'Avg_BPM', 'Resting_BPM', 'Session_Duration (hours)',\n",
    "                             'Water_Intake (liters)', 'SFat_Percentage', 'Workout_Frequency (days/week)', 'Calories_Burned']])\n",
    "\n",
    "gym_test_scale[['LWeight', 'Height (m)', 'Max_BPM', 'Avg_BPM', 'Resting_BPM', 'Session_Duration (hours)',\n",
    "                             'Water_Intake (liters)', 'SFat_Percentage', 'Workout_Frequency (days/week)', 'Calories_Burned']] = scaler.transform(gym_test_scale[['LWeight', 'Height (m)', 'Max_BPM', 'Avg_BPM', 'Resting_BPM', 'Session_Duration (hours)',\n",
    "                             'Water_Intake (liters)', 'SFat_Percentage', 'Workout_Frequency (days/week)', 'Calories_Burned']])\n",
    "\n",
    "\n",
    "# Create X_train_exp_level, X_test_exp_level, y_train_exp_level, y_test_exp_level\n",
    "X_train_exp_level = gym_train.drop(columns=['Experience_Level'])\n",
    "X_train_exp_level_scale = gym_train_scale.drop(columns=['Experience_Level'])\n",
    "y_train_exp_level = gym_train['Experience_Level']\n",
    "X_test_exp_level = gym_test.drop(columns=['Experience_Level'])\n",
    "X_test_exp_level_scale = gym_test_scale.drop(columns=['Experience_Level'])\n",
    "y_test_exp_level = gym_test['Experience_Level']\n",
    "\n",
    "# Create X_train_calories, X_test_calories, y_train_calories, y_test_calories\n",
    "X_train_calories = gym_train.drop(columns=['Calories_Burned'])\n",
    "X_train_calories_scale = gym_train_scale.drop(columns=['Calories_Burned'])\n",
    "y_train_calories = gym_train['Calories_Burned']\n",
    "X_test_calories = gym_test.drop(columns=['Calories_Burned'])\n",
    "X_test_calories_scale = gym_test_scale.drop(columns=['Calories_Burned'])\n",
    "y_test_calories = gym_test['Calories_Burned']\n",
    "\n",
    "print(\"Data loaded and preprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction de Calories Burned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_calories_dummy = pd.get_dummies(X_train_calories, columns=['Gender', 'Workout_Type'], drop_first=True)\n",
    "\n",
    "X_test_calories_dummy = pd.get_dummies(X_test_calories, columns=['Gender', 'Workout_Type'], drop_first=True)\n",
    "\n",
    "\n",
    "X_train_calories_dummy1 = pd.get_dummies(X_train_calories, drop_first=True)\n",
    "X_test_calories_dummy1 = pd.get_dummies(X_test_calories, drop_first=True)\n",
    "# Normalisation des données - scaled = Scale + Dummies alors que scale = just scale\n",
    "X_train_calories_scaled = scaler.fit_transform(X_train_calories_dummy1)\n",
    "X_test_calories_scaled = scaler.transform(X_test_calories_dummy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(gym_train.head().style.background_gradient(cmap='YlGnBu', low=0, high=0, axis=0))\n",
    "# display unique values of categorical columns\n",
    "display(gym_train.info())\n",
    "for col in gym_train.select_dtypes(include='category').columns:\n",
    "    print(col, gym_train[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(gym_train.head().style.background_gradient(cmap='YlGnBu', low=0, high=0, axis=0))\n",
    "# display unique values of categorical columns\n",
    "display(gym_train.info())\n",
    "for col in gym_train.select_dtypes(include='category').columns:\n",
    "    print(col, gym_train[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle Linéaire : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importer les bibliothèques nécessaires\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 2. Créer un modèle de régression linéaire\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "\n",
    "#calcul du temps d'entraînement\n",
    "import time\n",
    "start_time = time.time()\n",
    "# Entraînement du modèle\n",
    "# 3. Entraîner le modèle sur les données d'entraînement\n",
    "linear_model.fit(X_train_calories_scaled, y_train_calories)\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement : {end_time - start_time} secondes\")\n",
    "# 4. Faire des prédictions sur l'échantillon de test (X_test_scaled)\n",
    "#y_pred_calories = linear_model.predict(X_test_calories_scaled)\n",
    "y_pred_train_calories = linear_model.predict(X_train_calories_scaled)\n",
    "y_pred_test_calories = linear_model.predict(X_test_calories_scaled)\n",
    "# 5. Évaluer la performance du modèle\n",
    "# Coefficient de détermination R²\n",
    "r2_test = r2_score(y_test_calories, y_pred_test_calories)\n",
    "r2_train = r2_score(y_train_calories, y_pred_train_calories)\n",
    "print(f\"R² test: {r2_test}\")\n",
    "print(f\"R² train: {r2_train}\")\n",
    "\n",
    "# Erreur quadratique moyenne (MSE)\n",
    "mse = mean_squared_error(y_test_calories, y_pred_test_calories)\n",
    "print(f\"MSE: {mse}\")\n",
    "\n",
    "# 6. Afficher les coefficients du modèle\n",
    "print(\"Coefficients du modèle : \", linear_model.coef_)\n",
    "print(\"Intercept du modèle : \", linear_model.intercept_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train_calories, y_pred_train_calories, color='green', alpha=0.5, label='scikit-learn Regression Predictions')\n",
    "plt.plot([y_train_calories.min(), y_pred_train_calories.max()], [y_train_calories.min(), y_pred_train_calories.max()], 'k--', lw=2)\n",
    "plt.scatter(y_test_calories, y_pred_test_calories, color='blue', alpha=0.6)\n",
    "plt.plot([y_test_calories.min(), y_test_calories.max()], [y_test_calories.min(), y_test_calories.max()], color='red', lw=2)  # Ligne idéale\n",
    "plt.xlabel(\"Calories réelles\")\n",
    "plt.ylabel(\"Calories prédites\")\n",
    "plt.title(\"Prédictions vs Valeurs réelles\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performances du modèle\n",
    "\n",
    "R² = 0.978 :\n",
    "Le modèle explique 97.8% de la variance des calories brûlées. Cette valeur exceptionnellement élevée pourrait indiquer un surapprentissage (overfitting), surtout si le modèle a beaucoup de variables (18 coefficients ici).\n",
    "On remarque également que les points verts (entraînement) et bleus (test) semblent bien alignés, ce qui suggère une bonne performance globale du modèle. Toutefois, pour obtenir une analyse complète, il faudrait tracer résidus vs prédictions pour vérifier la répartition uniforme des résidus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calcul des résidus\n",
    "residuals_train = y_train_calories - y_pred_train_calories\n",
    "residuals_test = y_test_calories - y_pred_test_calories\n",
    "\n",
    "# Création d'une seule figure\n",
    "plt.figure(figsize=(8, 6))  # Ajuste la taille selon tes besoins\n",
    "\n",
    "# 1. Résidus vs Valeurs ajustées\n",
    "sns.residplot(x=y_pred_train_calories, y=residuals_train, lowess=True, \n",
    "              line_kws={'color': 'red', 'lw': 1})\n",
    "\n",
    "# Ajout de la ligne horizontale à zéro\n",
    "plt.axhline(0, color='black', linestyle='dotted', alpha=0.6)\n",
    "\n",
    "# Ajout des labels et du titre\n",
    "plt.xlabel(\"Fitted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Fitted\")\n",
    "\n",
    "# Affichage de la figure\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forme en banane dans le graphique des résidus (Residuals vs Fitted) révèle une non-linéarité non capturée par le modèle.Ce qui nous indique que la valeur du score R² est trompeuse. En effet, le R² mesure la variance expliquée, pas la justesse des prédictions. Un modèle peut, donc, avoir un R² élevé tout en ayant des erreurs systématiques. Le modèle linéaire est inadéquat pour capturer la vraie relation dans les données, malgré un R² élevé. Ainsi, pour améliorer la généralisation du modèle et identifier les variables réellement influentes, une approche de régularisation s’impose. C’est ici que la régression Lasso (Least Absolute Shrinkage and Selection Operator) entre en jeu. \n",
    "\n",
    "Donc, maintenant, nous allons passer à l’implémentation de Lasso pour voir comment il améliore (ou non) la robustesse du modèle, malgré les limites structurelles de la linéarité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord avec un lambda quelconque puis avec un lambda choisi par validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso\n",
    "lasso1= Lasso(alpha=10)\n",
    "# calcul du temps d'entraînement\n",
    "\n",
    "start_time = time.time()\n",
    "# Entraînement du modèle\n",
    "lasso1.fit(X_train_calories_scaled, y_train_calories)\n",
    "train_score_lasso1=lasso1.score(X_train_calories_scaled, y_train_calories)\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement : {end_time - start_time} secondes\")\n",
    "test_score_lasso1=lasso1.score(X_test_calories_scaled, y_test_calories)\n",
    "\n",
    "print(\"The train score for ls model is {}\".format(train_score_lasso1))\n",
    "print(\"The test score for ls model is {}\".format(test_score_lasso1))\n",
    "# print the lasso coefficient with the name of the variable next to it\n",
    "\n",
    "\n",
    "coef_calories_lasso1 = pd.Series(lasso1.coef_, index=X_train_calories_dummy1.columns)\n",
    "coef_calories_lasso1.sort_values().plot(kind='barh', figsize=(10, 6))\n",
    "plt.title('Coefficients du modèle Lasso pour Calories Burned')\n",
    "plt.show()\n",
    "# Afficher le nombre de variables conservées et éliminées\n",
    "print(f\"Lasso conserve {sum(coef_calories_lasso1 != 0)} variables et en supprime {sum(coef_calories_lasso1 == 0)}\")\n",
    "# print the coefficients of lasso1\n",
    "#print(\"Coefficients du modèle Lasso : \", coef_calories_lasso1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Appliquer Lasso avec validation croisée pour trouver le meilleur alpha\n",
    "#lasso = LassoCV(cv=5, random_state=1234, max_iter=10000)  # 5-fold cross-validation\n",
    "start_time = time.time()\n",
    "lasso = LassoCV(cv=5, alphas=np.array(range(1, 50, 1)) / 20., n_jobs=-1, random_state=13).fit(X_train_calories_scaled, y_train_calories)\n",
    "lasso.fit(X_train_calories_scaled, y_train_calories)\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement : {end_time - start_time} secondes\")\n",
    "\n",
    "# Coefficient optimal alpha sélectionné par LassoCV\n",
    "optimal_alpha = lasso.alpha_\n",
    "print(f\"Optimal alpha: {optimal_alpha}\")\n",
    "\n",
    "# Coefficients du modèle Lasso\n",
    "coef_calories_lasso = pd.Series(lasso.coef_, index=X_train_calories_dummy1.columns)\n",
    "\n",
    "# Afficher les coefficients du modèle Lasso\n",
    "print(\"Coefficients du modèle Lasso pour Calories Burned:\")\n",
    "print(coef_calories_lasso)\n",
    "\n",
    "# Afficher le nombre de variables conservées et éliminées\n",
    "print(f\"Lasso conserve {sum(coef_calories_lasso != 0)} variables et en supprime {sum(coef_calories_lasso == 0)}\")\n",
    "\n",
    "# Tracer les coefficients\n",
    "coef_calories_lasso.sort_values().plot(kind='barh', figsize=(10, 6))\n",
    "plt.title('Coefficients du modèle Lasso pour Calories Burned')\n",
    "plt.show()\n",
    "\n",
    "# Prédictions avec le modèle Lasso\n",
    "y_pred_lasso = lasso.predict(X_test_calories_scaled)\n",
    "\n",
    "# Calcul de l'erreur quadratique moyenne pour évaluer les performances du modèle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_lasso_test = mean_squared_error(y_test_calories, y_pred_lasso)\n",
    "\n",
    "print(f\"Test Mean Squared Error (MSE) pour Lasso pour l'échantillon de test: {mse_lasso_test}\")\n",
    "\n",
    "train_score_lasso= lasso.score(X_train_calories_scaled, y_train_calories)\n",
    "test_score_lasso= lasso.score(X_test_calories_scaled, y_test_calories)\n",
    "print(\"The train score for ls model is {}\".format(train_score_lasso))\n",
    "print(\"The test score for ls model is {}\".format(test_score_lasso))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performances du modèle\n",
    "\n",
    "- On obtient un MSE = 1638.14. On a donc une légère amélioration par rapport au modèle linéaire non régularisé (MSE=1679.54). Cependant, cette différence minime suggère que la régularisation Lasso réduit légèrement le surapprentissage.Toutefois, Le problème fondamental de non-linéarité (forme en banane des résidus) persiste, limitant les gains de performance. Ceci est visible dans le graphe des résidus ci-dessous, où l'on observe un profil en banane.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracé des résidus\n",
    "residuals_lasso = y_test_calories - y_pred_lasso\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_calories, residuals_lasso, color='blue', alpha=0.6)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Valeurs réelles\")\n",
    "plt.ylabel(\"Résidus\")\n",
    "plt.title(\"Résidus du modèle Lasso\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- On a un alpha optimal = 0.8 :Une pénalité L1 relativement forte, ce qui explique pourquoi 11 variables sur 18 ont été éliminées (coefficients à zéro).\n",
    "\n",
    "### Interpretation des résultats: \n",
    "\n",
    "#### Relation Session_Duration - Calories Burned\n",
    "- On remarque, d'après le graphe, que la variable Session_Duration domine clairement, c'est à dire qu'une augmentation d’1 heure de la durée de la séance entraîne une augmentation prédite de 243 calories brûlée. Donc, plus la séance est longue, plus le corps puise dans ses réserves énergétiques (glycogène et lipides).\n",
    "\n",
    "Les activités prolongées (ex : cardio, endurance) sollicitent le métabolisme aérobie, favorisant une dépense calorique cumulative.\n",
    "\n",
    "- Remarque: Ce coefficient élevé pourrait aussi refléter une corrélation indirecte (ex : les séances longues incluent souvent des exercices intenses).\n",
    "\n",
    "#### Différence homme femme \n",
    "-  Les hommes brûlent 40.9 calories de plus que les femmes à caractéristiques égales.\n",
    "    Ceci pourrait être dû au fait que les hommes ont généralement une masse musculaire plus élevée, qui consomme plus de calories au repos et à l’effort.Les différences hormonales (testostérone) favorisent un métabolisme énergétique plus actif.\n",
    "\n",
    "- Remarque: Ce coefficient pourrait aussi refléter des biais comportementaux (ex : les hommes choisissent des entraînements plus intenses non mesurés dans les données)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution du MSE en fonction de lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, LassoLarsCV\n",
    "model = LassoCV(cv=5, alphas=np.array(range(1,200,1))/10.,n_jobs=-1,random_state=13).fit(X_train_calories_scaled, y_train_calories)\n",
    "m_log_alphas = np.log10(model.alphas_)\n",
    "\n",
    "plt.figure()\n",
    "# ymin, ymax = 2300, 3800\n",
    "plt.plot(m_log_alphas, model.mse_path_, ':')\n",
    "plt.plot(m_log_alphas, model.mse_path_.mean(axis=-1), 'k',\n",
    "         label='MSE moyen', linewidth=2)\n",
    "plt.axvline(np.log10(model.alpha_), linestyle='--', color='k',\n",
    "            label='alpha: optimal par VC')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('log(alpha)')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE de chaque validation: coordinate descent ')\n",
    "plt.show()\n",
    "#le courbe noire correspond à la moyennes des 5 autres\n",
    "# on decoupe en 5 échantillons d'apprentissage d'ou les 5 courbes \n",
    "# Plot the coefficients as a function of -log(alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque une zone où la MSE est relativement basse et stable autour d’un certain intervalle de alpha. Puis, quand alpha devient trop grand (régularisation trop forte), la MSE monte en flèche (le modèle est trop contraint, sous-apprentissage).\n",
    "\n",
    "À l’opposé, quand alpha est trop petit, la régularisation est quasi nulle : on risque un sur-apprentissage (même si, parfois, la MSE peut rester relativement stable dans cette zone si le dataset n’est pas trop bruyant).\n",
    "\n",
    "Le point choisi par la validation croisée est un compromis : il vise à réduire le nombre de coefficients non nuls (pour la parcimonie) tout en conservant une bonne performance (basse MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from sklearn.linear_model import lasso_path\n",
    "\n",
    "# Calculer le chemin du Lasso\n",
    "alphas_lasso, coefs_lasso, _ = lasso_path(X_train_calories_scaled, y_train_calories, alphas=np.array(range(1, 400, 1)))\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "# Styles pour les lignes\n",
    "styles = cycle(['-', '--', '-.', ':'])\n",
    "\n",
    "# Log des alphas\n",
    "log_alphas_lasso = np.log10(alphas_lasso)\n",
    "\n",
    "# Tracer les coefficients\n",
    "for coef_l, s in zip(coefs_lasso, styles):\n",
    "    plt.plot(log_alphas_lasso, coef_l, linestyle=s, c='b')\n",
    "\n",
    "# Ajouter une ligne verticale pour l'alpha optimal\n",
    "plt.axvline(optimal_alpha, color='red', linestyle='--', label=f'Optimal alpha: {optimal_alpha}')\n",
    "\n",
    "# Ajouter des labels et une légende\n",
    "plt.xlabel('Log(alpha)')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.legend()\n",
    "plt.title('Lasso Path with Optimal Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique illustre le mécanisme de régularisation L1 propre à la régression Lasso : lorsque le paramètre de régularisation *alpha* augmente, la contrainte de parcimonie s'intensifie, conduisant progressivement les coefficients les moins informatifs vers zéro. Ce comportement est intrinsèque à l'algorithme, qui privilégie un **modèle simplifié** (moins de variables) au détriment d'une légère dégradation de la précision. En d'autres termes, un *alpha* élevé renforce la pénalisation des coefficients, favorisant ainsi un **équilibre optimal entre simplicité interprétative et généralisation**, au prix d'un biais accru. Cela traduit directement le compromis biais-variance au cœur de l'optimisation du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyennes et std des scores pour chaque alpha\n",
    "mse_path = model.mse_path_.mean(axis=1)\n",
    "stds = model.mse_path_.std(axis=1)\n",
    "alphas = model.alphas_\n",
    "\n",
    "# Index de l'erreur minimale\n",
    "min_idx = np.argmin(mse_path)\n",
    "\n",
    "# lambda_min\n",
    "alpha_min = alphas[min_idx]\n",
    "\n",
    "# lambda_1se = plus grand alpha avec erreur ≤ (erreur min + 1 std)\n",
    "threshold = mse_path[min_idx] + stds[min_idx]\n",
    "alpha_1se = max(alphas[mse_path <= threshold])\n",
    "\n",
    "# Refit pour alpha_min\n",
    "lasso_min = Lasso(alpha=alpha_min, max_iter=10000)\n",
    "start_time = time.time()\n",
    "lasso_min.fit(X_train_calories_scaled, y_train_calories)\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement pour alpha_min : {end_time - start_time} secondes\")\n",
    "\n",
    "non_zero_min = (lasso_min.coef_ != 0).sum()\n",
    "r2_min = lasso_min.score(X_test_calories_scaled, y_test_calories)\n",
    "# Refit pour alpha_1se\n",
    "lasso_1se = Lasso(alpha=alpha_1se, max_iter=10000)\n",
    "start_time = time.time()\n",
    "lasso_1se.fit(X_train_calories_scaled, y_train_calories)\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement pour alpha_1se : {end_time - start_time} secondes\")\n",
    "non_zero_1se = (lasso_1se.coef_ != 0).sum()\n",
    "r2_1se = lasso_1se.score(X_test_calories_scaled, y_test_calories)\n",
    "# Affichage des résultats\n",
    "print(f\"alpha_min (λ_min) = {alpha_min:.6f}\")\n",
    "print(f\"  -> MSE moyen : {mse_path[min_idx]:.6f}\")\n",
    "print(f\"  -> Écart-type : {stds[min_idx]:.6f}\")\n",
    "print(f\"  -> Nb variables non nulles : {non_zero_min}\")\n",
    "print(f\"  -> R² : {r2_min:.6f}\")\n",
    "# Trouver l'indice correspondant à alpha_1se\n",
    "idx_1se = list(alphas).index(alpha_1se)\n",
    "\n",
    "print(f\"\\nalpha_1se (λ_1se) = {alpha_1se:.6f}\")\n",
    "print(f\"  -> MSE moyen : {mse_path[idx_1se]:.6f}\")\n",
    "print(f\"  -> Écart-type : {stds[idx_1se]:.6f}\")\n",
    "print(f\"  -> Nb variables non nulles : {non_zero_1se}\")\n",
    "print(f\"  -> R² : {r2_1se:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons \n",
    "\n",
    "a. Alpha_min (λ_min = 0.8)\n",
    "- Pour λ_min = 0.8 et MSE moyen = 1629.17 :\n",
    "C'est l'erreur minimale moyenne obtenue par validation croisée.\n",
    "C'est la valeur de  λ qui donne les meilleures performances prédictives (modèle le plus précis).\n",
    "\n",
    "- Écart-type = 139.26 :\n",
    "Indique la variabilité des erreurs entre les folds de validation croisée.\n",
    "Une valeur élevée suggère que le modèle est instable (sensible aux variations des données d'entraînement).\n",
    "\n",
    "- 12 variables non nulles :\n",
    "Le modèle garde 12 coefficients non nuls → modèle complexe mais précis.\n",
    "\n",
    "b. Alpha_1se (λ_1se = 5.7)\n",
    "- λ_1se = 5.7 et MSE moyen = 1764.87 (+8.3% vs λ_min) :\n",
    "L'erreur est dans l'intervalle [λ_min - 1SE, λ_min + 1SE] → considérée comme statistiquement équivalente à l'erreur minimale.\n",
    "\n",
    "- Écart-type = 241.99 :\n",
    "Variabilité accrue → le modèle simplifié est plus sensible aux fluctuations des données.\n",
    "\n",
    "- 5 variables non nulles :\n",
    "Le modèle élimine 7 variables → modèle interprétable mais potentiellement moins précis.\n",
    "\n",
    "Ces valeurs sont logiques vu que Alpha_1se represente la plus grande valeur de lambda dont l’erreur est à moins d’un écart-type de l’erreur minimale(favorise un modèle plus simple) et que Alpha_min minimise l’erreur de validation croisée (MSE) (donne le meilleur ajustement possible sur les données de validation). Toutefois, nous préférons généralement afficher ces coefficients en R et pas en python. Ceci est dû à l'absence de λ_1se natif en python\n",
    "(Scikit-learn ne calcule pas automatiquement λ_1se, contrairement à glmnet en R)\n",
    "→ Calcul manuel sujet à des erreurs (ex: gestion des intervalles de confiance).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle quadratique et ordre élevé\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# pipeline pour le Lasso avec les interactions\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(interaction_only=True, include_bias=False)),\n",
    "    ('scaler', StandardScaler()),  # Good practice before Lasso\n",
    "    ('lasso', Lasso(max_iter=10000))\n",
    "])\n",
    "\n",
    "scoring = {\n",
    "    'r2': 'r2',\n",
    "    'neg_mse': 'neg_mean_squared_error'\n",
    "}\n",
    "\n",
    "# grille de paramètres pour le Lasso\n",
    "param_grid = {\n",
    "    'poly__degree': [1, 2, 3],      # Tune the interaction degree\n",
    "    'lasso__alpha': np.logspace(-2, 1, 10)  # Tune the Lasso strength\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='r2',  # On choisit sur quelle métrique choisir le best_estimator_\n",
    "    cv=5,\n",
    "    return_train_score=True,\n",
    "    n_jobs=6 # run en parallèle\n",
    ")\n",
    "\n",
    "grid.fit(X_train_calories_scaled, y_train_calories)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul du temps d'entrainement pour une configuration spécifique\n",
    "\n",
    "# Création du pipeline avec les hyperparamètres spécifiques\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(interaction_only=True, include_bias=False, degree=2)), # Degré fixé à 2\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso(alpha=0.1, max_iter=10000)) # Alpha fixé à 0.1\n",
    "])\n",
    "\n",
    "# Mesure du temps pour UNE configuration\n",
    "start_time = time.time()\n",
    "pipeline.fit(X_train_calories_scaled, y_train_calories)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Temps d'entraînement pour degree=2 et alpha=0.1 : {end_time - start_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "filtered_row = results[results['params'] == {'lasso__alpha': 1.0, 'poly__degree': 3}]\n",
    "filtered_row[['mean_test_neg_mse']]\n",
    "print(\"Best model R² (Cross Validation):\", grid.best_score_)\n",
    "print(\"Best model MSE (Cross Validation):\", -filtered_row['mean_test_neg_mse'].values[0] , \"\\n\")\n",
    "\n",
    "print(\"Best model test R²:\", grid.score(X_test_calories_scaled, y_test_calories))\n",
    "print(\"Best model test MSE:\", mean_squared_error(y_test_calories, best_model.predict(X_test_calories_scaled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Récupérer le PolynomialFeatures entraîné\n",
    "poly = best_model.named_steps['poly']\n",
    "\n",
    "# 2. Récupérer le modèle Lasso entraîné\n",
    "lasso = best_model.named_steps['lasso']\n",
    "\n",
    "# 3. Construire les noms des features\n",
    "feature_names = poly.get_feature_names_out(input_features=X_train_calories_dummy1.columns)\n",
    "\n",
    "# 4. Associer chaque feature à son coefficient\n",
    "coefs = pd.Series(lasso.coef_, index=feature_names)\n",
    "\n",
    "# 5. Afficher ou trier les coefficients\n",
    "pd.set_option('display.max_rows', None)\n",
    "coefs = coefs.sort_values()\n",
    "print(coefs)\n",
    "coefs = coefs[coefs != 0]  # Garder uniquement les coefficients non nuls\n",
    "\n",
    "# 6. Plot\n",
    "coefs.plot(kind='barh', figsize=(10, 12))\n",
    "plt.title('Coefficients Lasso avec interactions')\n",
    "plt.show()\n",
    "#plot the residuals for the lasso model\n",
    "y_fitted_lasso = best_model.predict(X_train_calories_scaled)\n",
    "y_fitted_lasso_test= best_model.predict(X_test_calories_scaled)\n",
    "print(y_fitted_lasso.shape)\n",
    "print(y_test_calories.shape)\n",
    "residuals_lasso = y_train_calories  - y_fitted_lasso\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x=y_fitted_lasso, y=residuals_lasso, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Valeurs réelles')\n",
    "plt.ylabel('Résidus')\n",
    "plt.title('Résidus du modèle Lasso avec interactions')\n",
    "plt.show()\n",
    "\n",
    "#print(\"Best model test R²:\", grid.score(X_test_calories_scaled, y_test_calories))\n",
    "mse_lasso_quadratic_test = mean_squared_error(y_test_calories, y_fitted_lasso_test)\n",
    "\n",
    "print(f\"Test Mean Squared Error (MSE) pour Lasso pour l'échantillon de test: {mse_lasso_quadratic_test}\")\n",
    "#compute the score for the lasso model from the previous\n",
    "\n",
    "train_score_lasso= best_model.score(X_train_calories_scaled, y_train_calories)\n",
    "test_score_lasso= best_model.score(X_test_calories_scaled, y_test_calories)\n",
    "#print(\"The train score for ls model is {}\".format(train_score_lasso))\n",
    "print(\"The test score for ls model is {}\".format(test_score_lasso))\n",
    "\n",
    "\n",
    "\n",
    "#print(\"The train score for ls model is {}\".format(train_score_lasso))\n",
    "print(\"The test score for ls model is {}\".format(test_score_lasso))\n",
    "\"\"\"\n",
    "residuals_train = y_train_calories - y_pred_train_calories\n",
    "residuals_test = y_test_calories - y_pred_test_calories\n",
    "\n",
    "# Création d'une seule figure\n",
    "plt.figure(figsize=(8, 6))  # Ajuste la taille selon tes besoins\n",
    "y_pred_calories = linear_model.predict(X_test_calories_scaled)\n",
    "y_pred_train_calories = linear_model.predict(X_train_calories_scaled)\n",
    "y_pred_test_calories = linear_model.predict(X_test_calories_scaled)\n",
    "# 1. Résidus vs Valeurs ajustées\n",
    "sns.residplot(x=y_pred_train_calories, y=residuals_train, lowess=True, \n",
    "              line_kws={'color': 'red', 'lw': 1})\n",
    "\"\"\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🔎 **Interprétation du Modèle Lasso avec Interactions (Polynomial + Lasso)**\n",
    "\n",
    "Ce modèle repose sur un encodage polynomial avec interactions uniquement (`interaction_only=True`, degré 3), suivi d’une régularisation L1 (`Lasso`). Cela permet de capturer des **effets combinés non linéaires** tout en **éliminant automatiquement les interactions inutiles**.\n",
    "\n",
    "#####  Performances\n",
    "- **R² test** = **0.993**, **MSE test** ≈ **542**\n",
    "- Gain substantiel par rapport au Lasso simple (R² ≈ 0.979, MSE ≈ 1638)\n",
    "- Ce modèle capture donc beaucoup mieux la complexité des relations entre variables.\n",
    "\n",
    "#### Temps de Calcul (1 minute)\n",
    "Complexité justifiée : Bien que plus lent qu’un modèle linéaire (quelques secondes), le gain en performance valide l’utilisation d’un modèle quadratique.\n",
    "\n",
    "Optimisation : Le Lasso réduit la complexité en éliminant les termes non pertinents, équilibrant précision et parcimonie.\n",
    "#####  Interprétation des principales interactions retenues\n",
    "\n",
    "Les **coefficients positifs** indiquent des interactions qui **augmentent** la prédiction de `Calories_Burned`, et les **négatifs** celles qui la **diminuent** :\n",
    "\n",
    "---\n",
    "\n",
    "##### Quelques interactions dominantes positives :\n",
    "\n",
    "- **`Avg_BPM × Session_Duration`** → **+21.44**\n",
    "  > Synergie intensité/durée : les longues séances à haut BPM amplifient la dépense calorique (effet non-linéaire critique).\n",
    "\n",
    "- **`Session_Duration (hours) Gender_Male`** → **+11.42**\n",
    "  > Les hommes tirent un bénéfice calorique supplémentaire des sessions longues, possiblement grâce à une endurance musculaire supérieure.\n",
    "\n",
    "##### Quelques interactions dominantes négatives :\n",
    "\n",
    "- **`Age × Session_Duration`** → **−10.6**\n",
    "  > À durée d'entrainement équivalents, l'âge **réduit fortement** la dépense calorique. Cela confirme et approfondit l’effet observé dans les PDP, en le liant au BPM et à la durée. Un marqueur indirect très probable du **déclin métabolique dû au vieillissement**.\n",
    "\n",
    "- **`Age × Avg_BPM`** → **−2.35**\n",
    "  >  À fréquence cardiaque équivalente, les seniors brûlent moins, possiblement dû à une VO₂ max (débit maximum d'oxygène) réduite.\n",
    "\n",
    "\n",
    "#### Conclusion \n",
    "\n",
    "> *Le modèle polynomial régularisé par Lasso améliore significativement la prédiction (R² ≈ 0.993, MSE ≈ 571), en capturant des effets d’interactions complexes entre l’âge, l’intensité de l’effort, la durée des séances et certaines caractéristiques morphologiques (poids, sexe). Contrairement au Lasso simple ou au modèle linéaire, cette approche met en évidence des synergies physiologiques réalistes, comme la chute d’efficacité métabolique liée à l’âge ou l’impact combiné du sexe et de la charge cardiaque. Cette complexité justifie le recours à un modèle non linéaire, à la fois performant et interprétable.*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, nous étudierons brièvement l'effet d'une pénalisation plus stricte sur le modèle via Ridge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1) Instanciation sans n_jobs ni random_state\n",
    "start_time = time.time()\n",
    "ridgereg = RidgeCV(alphas=np.arange(1, 50) / 20., cv=5)\n",
    "\n",
    "# 2) Entraînement\n",
    "\n",
    "ridgereg.fit(X_train_calories_scaled, y_train_calories)\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement : {end_time - start_time} secondes\")\n",
    "# 3) Alpha optimal\n",
    "optimal_alpha = ridgereg.alpha_\n",
    "print(f\"Optimal alpha: {optimal_alpha}\")\n",
    "\n",
    "# 4) Coefficients\n",
    "coef_calories_ridge = pd.Series(ridgereg.coef_, index=X_train_calories_dummy1.columns)\n",
    "print(\"Coefficients du modèle Ridge pour Calories Burned:\")\n",
    "print(coef_calories_ridge)\n",
    "\n",
    "# 5) Comme Ridge ne met quasiment jamais un coefficient strictement à 0, \n",
    "#    le comptage « conservé / supprimé » n’est pas très significatif, mais :\n",
    "print(f\"Nombre de coefficients non nuls : {sum(coef_calories_ridge != 0)}\")\n",
    "\n",
    "# 6) Tracé\n",
    "coef_calories_ridge.sort_values().plot(kind='barh', figsize=(10, 6))\n",
    "plt.title('Coefficients du modèle Ridge pour Calories Burned')\n",
    "plt.show()\n",
    "\n",
    "# 7) Prédiction et MSE\n",
    "y_pred_ridge = ridgereg.predict(X_test_calories_scaled)\n",
    "mse_ridge = mean_squared_error(y_test_calories, y_pred_ridge)\n",
    "print(f\"MSE pour Ridge : {mse_ridge:.4f}\")\n",
    "\n",
    "# 8) R² (score) entraînement et test\n",
    "train_score_ridge = ridgereg.score(X_train_calories_scaled, y_train_calories)\n",
    "test_score_ridge  = ridgereg.score(X_test_calories_scaled,  y_test_calories)\n",
    "print(f\"Train R² pour Ridge : {train_score_ridge:.4f}\")\n",
    "print(f\"Test  R² pour Ridge : {test_score_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle Ridge obtient un MSE de 1 661,23, un R² entraînement de 0,9791 et un R² test de 0,9787. Ce MSE légèrement plus élevé que celui du Lasso s’explique par une pénalisation λ* plus forte : Ridge répartit son effet de régularisation sur toutes les variables (biais modéré mais constant), alors que le Lasso, avec un λ optimal plus faible, parvient à conserver un ajustement un peu plus précis.\n",
    "\n",
    "Cependant, les performances des deux modèles linéaires restent très proches :\n",
    "\n",
    "Lasso (λ_min) : MSE test ≃ 1 638,14, R² test ≃ 0,9790\n",
    "\n",
    "Ridge : MSE test ≃ 1 661,23, R² test ≃ 0,9787\n",
    "\n",
    "Enfin, le Lasso quadratique (avec interactions) surpasse nettement ces deux approches linéaires, avec un MSE test ≃ 570,61 et un R² test ≃ 0,9927, grâce à sa capacité à capturer des relations non linéaires entre les variables mais reste un peu plus lent niveau temps d'entrainement \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir analysé les performances du modèle Lasso et de Ridge et identifié l'alpha optimal pour régulariser notre régression, nous allons maintenant explorer une approche alternative en utilisant la régression par vecteurs de support (SVR) afin de comparer ses performances et sa capacité à capturer des relations potentiellement non linéaires dans les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR SUR CALORIES BURNED : \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#calibrage des paramètres c et gamma\n",
    "\n",
    "param = [{'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']}]\n",
    "param_lin_opt= GridSearchCV(SVR(),param,refit=True,verbose=3)\n",
    "start_time = time.time()\n",
    "param_lin_opt.fit(X_train_calories_scaled,y_train_calories)\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement : {end_time - start_time} secondes\")\n",
    "print(param_lin_opt.best_params_)\n",
    "start_time = time.time()\n",
    "y_pred_svr_lin = param_lin_opt.predict(X_test_calories_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"Temps de prédiction : {end_time - start_time} secondes\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_calories, y_pred_svr_lin, color='darkorange', label='Prédictions vs Réelles')\n",
    "plt.plot([y_test_calories.min(), y_test_calories.max()], \n",
    "         [y_test_calories.min(), y_test_calories.max()], \n",
    "         color='navy', lw=2, linestyle='--', label='Parfaite prédiction')\n",
    "plt.xlabel('Valeurs Réelles (Calories_Burned)')\n",
    "plt.ylabel('Prédictions (Calories_Burned)')\n",
    "plt.legend()\n",
    "plt.title('SVR Linéaire - Comparaison Prédictions/Réelles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_score_lin= r2_score(y_test_calories,y_pred_svr_lin)\n",
    "print(f\"R² pour SVR lin: {R2_score_lin}\")\n",
    "mse_svr_lin = mean_squared_error(y_test_calories, y_pred_svr_lin)\n",
    "print(f\"MSE pour SVR poly: {mse_svr_lin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rbf=[{'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}]\n",
    "parmopt_rbf = GridSearchCV(SVR(), param_rbf, refit = True, verbose = 3)\n",
    "parmopt_rbf.fit(X_train_calories_scaled, y_train_calories)\n",
    "print(parmopt_rbf.best_params_)\n",
    "start_time = time.time()\n",
    "y_pred_svr_rbf = parmopt_rbf.predict(X_test_calories_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"Temps de prédiction : {end_time - start_time} secondes\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_calories, y_pred_svr_rbf, color='darkorange', label='Prédictions vs Réelles')\n",
    "plt.plot([y_test_calories.min(), y_test_calories.max()], \n",
    "         [y_test_calories.min(), y_test_calories.max()], \n",
    "         color='navy', lw=2, linestyle='--', label='Parfaite prédiction')\n",
    "plt.xlabel('Valeurs Réelles (Calories_Burned)')\n",
    "plt.ylabel('Prédictions (Calories_Burned)')\n",
    "plt.legend()\n",
    "plt.title('SVR rbf - Comparaison Prédictions/Réelles')\n",
    "plt.show()\n",
    "\n",
    "R2_score_rbf= r2_score(y_test_calories,y_pred_svr_rbf)\n",
    "print(f\"R² pour SVR rbf: {R2_score_rbf}\")\n",
    "mse_svr_rbf = mean_squared_error(y_test_calories, y_pred_svr_rbf)\n",
    "print(f\"MSE pour SVR rbf: {mse_svr_rbf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_poly=[{'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['poly']}]\n",
    "parmopt_poly = GridSearchCV(SVR(), param_poly, refit = True, verbose = 3)\n",
    "time_start = time.time()\n",
    "parmopt_poly.fit(X_train_calories_scaled, y_train_calories)\n",
    "time_end = time.time()\n",
    "print(f\"Temps d'entraînement : {time_end - time_start} secondes\")\n",
    "print(parmopt_poly.best_params_)\n",
    "\n",
    "y_pred_svr_poly = parmopt_poly.predict(X_test_calories_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_calories, y_pred_svr_poly, color='darkorange', label='Prédictions vs Réelles')\n",
    "plt.plot([y_test_calories.min(), y_test_calories.max()], \n",
    "         [y_test_calories.min(), y_test_calories.max()], \n",
    "         color='navy', lw=2, linestyle='--', label='Parfaite prédiction')\n",
    "plt.xlabel('Valeurs Réelles (Calories_Burned)')\n",
    "plt.ylabel('Prédictions (Calories_Burned)')\n",
    "plt.legend()\n",
    "plt.title('SVR poly - Comparaison Prédictions/Réelles')\n",
    "plt.show()\n",
    "\n",
    "R2_score_poly= r2_score(y_test_calories,y_pred_svr_poly)\n",
    "print(f\"R² pour SVR poly: {R2_score_poly}\")\n",
    "mse_svr_poly = mean_squared_error(y_test_calories, y_pred_svr_poly)\n",
    "print(f\"MSE pour SVR poly: {mse_svr_poly}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Performances des différents noyaux SVR**\n",
    "\n",
    "a. SVR avec noyau RBF (Radial Basis Function)\n",
    "R² = 0,992 et MSE = 636,57\n",
    "\n",
    "=> Le modèle RBF parvient à expliquer 99,2 % de la variance des calories brûlées, avec une erreur quadratique moyenne extrêmement basse.\n",
    "Ceci est dû au fait que le noyau RBF est capable de capturer des relations non linéaires complexes (par exemple, l’interaction entre la durée de séance et la fréquence cardiaque moyenne). Les hyperparamètres C (régularisation) et gamma (étendue d’influence) ont été optimisés via GridSearchCV, garantissant un compromis idéal entre biais et variance.\n",
    "\n",
    "b. SVR avec noyau linéaire\n",
    "R² = 0,977 et MSE = 1 790,89\n",
    "\n",
    "=> Le SVR linéaire offre également de bonnes performances , mais nettement inférieures au noyau RBF (erreur MSE beaucoup plus élevée).\n",
    "Ceci pourrait être dû au fait que\n",
    "\n",
    "c. SVR avec noyau polynomial\n",
    "R² = 0,949 et MSE = 3 952,21\n",
    "\n",
    "=> Les résultats sont bien plus faibles, avec une erreur environ 6 fois supérieure à celle du RBF.\n",
    "\n",
    "\n",
    "2. **Comparaison des Performances : Lasso Quadratique vs SVR RBF**\n",
    "\n",
    "| Critère               | Lasso Quadratique (Interactions) | SVR RBF              |\n",
    "|-----------------------|-----------------------------------|----------------------|\n",
    "| **MSE (Test)**        | **570.61**                        | 636.57              |\n",
    "| **R² (Test)**         | **0.9927**                        | 0.992               |\n",
    "| **Complexité**        | Modèle linéaire avec interactions | Modèle non linéaire |\n",
    "| **Interprétabilité**  | Coefficients explicables          | \"Boîte noire\"       |\n",
    "| **Flexibilité**       | Capte interactions spécifiques    | Adapté aux relations complexes/génériques |\n",
    "\n",
    "---\n",
    "\n",
    "#### **Points Clés :**\n",
    "1. **Performance Prédictive** :  \n",
    "   - Le **Lasso Quadratique** est légèrement meilleur en MSE (+10% d'erreur pour SVR RBF).  \n",
    "   - Les deux modèles ont un R² quasi identique (> 0.99), indiquant une explication quasi parfaite de la variance.\n",
    "\n",
    "2. **Equilibre Complexité/Interprétabilité** :  \n",
    "   - **Lasso Quadratique** : Moins flexible mais interprétable (coefficients des interactions analysables).  \n",
    "   - **SVR RBF** : Plus flexible mais difficile à expliquer (dépend de la fonction noyau).\n",
    "\n",
    "3. **Choix du modèle** :  \n",
    "   - **Lasso Quadratique** : Si l’on privilégie l’erreur quadratique minimale et la parcimonie  \n",
    "   - **SVR RBF** : Si l’on recherche avant tout la flexibilité pour capter des structures non-linéaires plus subtiles\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbres et Forest aléatoires\n",
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_calories_dummy = pd.get_dummies(X_train_calories, columns=['Gender', 'Workout_Type'], drop_first=True)\n",
    "\n",
    "X_test_calories_dummy = pd.get_dummies(X_test_calories, columns=['Gender', 'Workout_Type'], drop_first=True)\n",
    "\n",
    "# Normalisation des données - scaled = Scale + Dummies alors que scale = just scale\n",
    "X_train_calories_scaled = scaler.fit_transform(X_train_calories_dummy)\n",
    "X_test_calories_scaled = scaler.transform(X_test_calories_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Fit a regression tree model for Calories_Burned using dummy variables\n",
    "tree_reg_cal = DecisionTreeRegressor(random_state=randomseed, ccp_alpha=0.001)\n",
    "start_time = time.time()\n",
    "tree_reg_cal.fit(X_train_calories_dummy, y_train_calories)\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement : {end_time - start_time} secondes\")\n",
    "\n",
    "# Plot the tree\n",
    "plt.figure(figsize=(18, 12))\n",
    "plot_tree(tree_reg_cal, feature_names=X_train_calories_dummy.columns, filled=True, rounded=True, fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Compute MSE and R2 on training and test sets\n",
    "y_train_pred = tree_reg_cal.predict(X_train_calories_dummy)\n",
    "y_test_pred = tree_reg_cal.predict(X_test_calories_dummy)\n",
    "\n",
    "mse_train = mean_squared_error(y_train_calories, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test_calories, y_test_pred)\n",
    "r2_train = r2_score(y_train_calories, y_train_pred)\n",
    "r2_test = r2_score(y_test_calories, y_test_pred)\n",
    "\n",
    "print(\"MSE on training set: \", mse_train)\n",
    "print(\"MSE on test set: \", mse_test)\n",
    "print(\"R2 on training set: \", r2_train)\n",
    "print(\"R2 on test set: \", r2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : Nous avons initialement construit un arbre de régression avec un paramètre de complexité extrêmement faible (`cp = 0.01`). Comme attendu, ce modèle présente une structure profondément ramifiée, caractéristique d'un sur-apprentissage. Ce modèle présente queasiment aucun biais sur le jeu d’entraînement (R² = 0.999, MSE = 0.027), mais un écart significatif entre l’erreur d’entraînement et de test (MSE_test = 4484) révèle un sur-apprentissage. Toutefois, le R² sur le test reste élevé (0.934), indiquant que le modèle capture une part substantielle de la variance explicative, malgré sa complexité excessive. Le modèle d'arbre en Python est plus complexe qu'en R alors que nous utilisons un cp plus élevé (`cp=0.01`), tandis que R utilise un `cp=0.001`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for best cp \n",
    "\n",
    "scoring = {\n",
    "    'r2': 'r2',\n",
    "    'neg_mse': 'neg_mean_squared_error'\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'ccp_alpha': np.logspace(-4, 2, 15)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(tree_reg_cal, params, scoring=scoring, cv=5, refit='r2', n_jobs=-1)\n",
    "grid.fit(X_train_calories_dummy, y_train_calories)\n",
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# plot the results as a function of ccp_alpha\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(grid_results['param_ccp_alpha'], grid_results['mean_test_neg_mse'] * -1, label='MSE', marker='o')\n",
    "plt.xlabel('Complexity Parameter (alpha)')\n",
    "plt.ylabel('Cross-Validation Error')\n",
    "plt.title('Cross-Validation Error vs Complexity Parameter')\n",
    "plt.grid(True, which=\"both\", ls=\"-\")\n",
    "\n",
    "optimal_alpha = np.argmin(grid_results['mean_test_neg_mse'] * -1)\n",
    "plt.axvline(grid_results['param_ccp_alpha'][optimal_alpha], color='red', linestyle='--', label='Optimal alpha')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the tree\n",
    "plt.figure(figsize=(18, 12))\n",
    "tree_reg_cal_optimal = grid.best_estimator_\n",
    "plot_tree(tree_reg_cal_optimal, feature_names=X_train_calories_dummy.columns, filled=True, rounded=True, fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# display the dataframe with top 5 results from mean_test_neg_mse\n",
    "display(grid_results[['param_ccp_alpha', 'mean_test_neg_mse', 'std_test_neg_mse', 'rank_test_neg_mse']].sort_values(by='mean_test_neg_mse', ascending=False).head(5))\n",
    "# same for r2\n",
    "\n",
    "display(grid_results[['param_ccp_alpha', 'mean_test_r2', 'std_test_r2', 'rank_test_r2']].sort_values(by='mean_test_r2', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : Par validation croisée, nous avons déterminé que le meilleur paramètre d'élagage est `ccp ≈ 5.18`. L'arbre de regression résultant est moins complexe que le précédent, mais est encore trop ramifié, comme celui de R. Ce modèle est un peu moins performant que celui de R, avec un MSE calculé par cross-validation 5-fold de 5017 ici contre 4521 pour le modèle de R. Le R² est similaire dans les deux langages (~0.93) en revanche. Cela souligne que le modèle de régression est tout de même robuste, malgré la complexité de l'arbre.\n",
    "\n",
    "Nous allons pouvoir explorer d'autres méthodes d'arbres de décision, comme les forêts aléatoires et le boosting, qui sont souvent plus performantes que les arbres de décision simples. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forêts aléatoires\n",
    "\n",
    "#### Simple random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Créer et entraîner une forêt aléatoire\n",
    "rf_reg_cal = RandomForestRegressor(random_state=randomseed, oob_score=True)\n",
    "rf_reg_cal.fit(X_train_calories_dummy, y_train_calories)\n",
    "\n",
    "# Prédictions sur les ensembles d'entraînement et de test\n",
    "y_train_pred_rf = rf_reg_cal.predict(X_train_calories_dummy)\n",
    "y_test_pred_rf = rf_reg_cal.predict(X_test_calories_dummy)\n",
    "\n",
    "# Calculer le MSE et le R2\n",
    "mse_train_rf = mean_squared_error(y_train_calories, y_train_pred_rf)\n",
    "mse_test_rf = mean_squared_error(y_test_calories, y_test_pred_rf)\n",
    "r2_train_rf = r2_score(y_train_calories, y_train_pred_rf)\n",
    "r2_test_rf = r2_score(y_test_calories, y_test_pred_rf)\n",
    "\n",
    "print(\"Random Forest - OOB score :\", rf_reg_cal.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : Le modèle de base basique aléatoire de `scikit-learn` est construit avec 100 arbres, avec les paramètres `min_samples_split = 2` (nombre minimum d'élements pour considérer une décision) et `min_samples_leaf = 1` (nombre minimum d'élement dans une feuille). Ces paramètres sont les valeurs par défaut de `scikit-learn`, mais nous allons les optimiser par la suite. \n",
    "\n",
    "Le modèle est construit avec un échantillonnage bootstrap, ce qui signifie que chaque arbre est construit sur un sous-ensemble aléatoire des données d'entraînement. Cela nous permet d'extraire l'erreur OOB qui est calculé par défaut avec le score R² dans `scikit-learn`, alors qu'en R, elle est traditionnellement évaluée via la somme des résidus au carré (RSS, Residual Sum of Squares).\n",
    "\n",
    "Contrairement à R ou le paramètre à optimiser est `mtry` (nombre de variables considérées à chaque split), `scikit-learn` nous permet d'optimiser plusieurs hyperparamètres essentiels :\n",
    "- **`max_depth`** : la profondeur maximale de chaque arbre (plus un arbre est profond, plus il peut modéliser des interactions complexes, mais aussi surapprendre). \n",
    "- **`min_samples_split`** : le nombre minimum d'échantillons requis pour diviser un noeud. Plus il est grand, plus l’arbre est contraint et moins il risque de surapprendre.\n",
    "- **`min_samples_leaf`** : le nombre minimum d'échantillons nécessaires dans une feuille terminale. Cela permet d’éviter des feuilles trop petites, ce qui améliore la robustesse.\n",
    "- **`max_features`** : le nombre maximal de variables considérées pour chercher le meilleur split à chaque division (équivalent au `mtry` de R). Peut être fixé à un nombre entier, à une proportion de la taille du sample (`float` entre 0 et 1), ou aux valeurs prédéfinies `'sqrt'` : $\\sqrt{n_\\text{variables}}$ ou `'log2'` : $\\log_2(n_\\text{variables})$.\n",
    "- **`max_leaf_nodes`** : limite le nombre total de feuilles de l’arbre, forçant une structure plus simple.\n",
    "- **`ccp_alpha`** : le paramètre de coût-complexité pour l'élagage (post-pruning) ; plus `ccp_alpha` est grand, plus l'élagage sera fort.\n",
    "\n",
    "Enfin, il nous est également permis de choisir le **critère d’évaluation** de la qualité du split (`criterion`).   \n",
    "Alors qu’en R, la performance est évaluée via le **RSS** (Residual Sum of Squares), l’option la plus proche disponible dans `scikit-learn` est `friedman_mse`, conçue pour optimiser la variance résiduelle de manière similaire au RSS.  \n",
    "Ici, nous avons l'occasion de comparer l'impact du choix du critère (`friedman_mse` vs `squared_error`) sur la construction des arbres.  \n",
    "\n",
    "Nous observerons notamment l'effet sur la performance de généralisation (via le score OOB R²) ainsi que sur le temps d'apprentissage et d'élagage.\n",
    "Le score OOB étant uniquement calculé sur la métrique R² sous `scikit-learn`, le modèle optimal ne sera pas directement comparable aux mesures obtenues en R (RSS).\n",
    "\n",
    "Par ailleurs, ces hyperparamètres **sont interdépendants** : en pratique, optimiser l'hyperparamètre `max_leaf_nodes` peut réduire la nécessité d'élaguer l'arbre, ou la nécéssité de définir `max_depth`. \n",
    "\n",
    "Nous avons décidé de construire un modèle de forêt aléatoire avec les paramètres par défaut et optimiser les hyperparamètres `n_estimators` et `max_features` ainsi que le paramètre `ccp_alpha` pour l'élagage, que nous avons vu en cours, mais que nous avons pas appliqué dans le modèle de R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest avec élagage\n",
    "\n",
    "Comme les forêts aléatoires sont construits avec un échantillonnage bootstrap, nous pouvons estimer l'**erreur OOB (Out-Of-Bag) pour évaluer la performance du modèle**. Ainsi nous n'avons pas besoin d'utiliser la validation croisée pour évaluer le modèle et déterminer les meilleurs hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Définir le grille de paramètres\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': np.linspace(0.1, 1.0, 10),  # proportion du nombre total de variables\n",
    "    'ccp_alpha': [0.01, 0.1, 1.0, 5.0, 10.0],\n",
    "    'criterion': ['friedman_mse', 'squared_error'],  # Comparer plusieurs critères !\n",
    "    'oob_score': [True],\n",
    "}\n",
    "\n",
    "# Générer toutes les combinaisons possibles\n",
    "keys, values = zip(*param_grid.items())\n",
    "param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "# Fonction pour entraîner et évaluer\n",
    "def train_and_evaluate(params):\n",
    "    model = RandomForestRegressor(random_state=randomseed, **params)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_calories_dummy, y_train_calories)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'max_features': params['max_features'],\n",
    "        'ccp_alpha': params['ccp_alpha'],\n",
    "        'criterion': params['criterion'],\n",
    "        'oob_score': model.oob_score_,\n",
    "        'training_time_sec': elapsed_time,\n",
    "    }\n",
    "\n",
    "# Paralléliser\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(train_and_evaluate)(params) for params in param_combinations\n",
    ")\n",
    "\n",
    "# Convertir en DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Trier par oob_score décroissant\n",
    "results_df = results_df.sort_values(by='oob_score', ascending=False)\n",
    "\n",
    "# Afficher\n",
    "# display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_max_features = [0.9, 0.6, 0.4, 0.1]\n",
    "selected_ccp_alpha = [0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "# Créer 4 sous-graphiques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))  # 2x2 grid\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, alpha in enumerate(selected_ccp_alpha):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Sous-ensemble des résultats pour ce ccp_alpha\n",
    "    subset = results_df[results_df['ccp_alpha'] == alpha]\n",
    "    \n",
    "    for max_feat in selected_max_features:\n",
    "        # Prendre uniquement les lignes correspondant à un max_features donné\n",
    "        curve = subset[np.isclose(subset['max_features'], max_feat)]\n",
    "        # Trier par n_estimators pour des courbes bien propres\n",
    "        curve = curve.sort_values('n_estimators')\n",
    "        \n",
    "        ax.plot(curve['n_estimators'], curve['oob_score'], marker='o', label=f'max_features = {max_feat}')\n",
    "    \n",
    "    ax.set_title(f'OOB Score vs n_estimators (ccp_alpha = {alpha})')\n",
    "    ax.set_xlabel('n_estimators')\n",
    "    ax.set_ylabel('OOB R² Score')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parmi les 100 meilleures combinaisons, sortir les 10 plus longues à fitter et les 10 plus courtes\n",
    "best_results_df = results_df[results_df['oob_score'] > 0.974].sort_values(by='training_time_sec', ascending=False).copy()\n",
    "display(best_results_df.head(10))\n",
    "\n",
    "display(best_results_df.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Interprétation des résulats de la forêt aléatoire** :\n",
    "\n",
    "Nous avons réalisé une analyse fine de la performance de la forêt aléatoire en fonction de plusieurs hyperparamètres (`n_estimators`, `max_features`, `ccp_alpha`), en nous concentrant sur l'estimation de l'erreur de généralisation via l'**OOB score**.\n",
    "\n",
    "$\\rightarrow$ **Influence du critère de split (`criterion`)**\n",
    "\n",
    "En observant le tableau des résultats, nous constatons que **le choix du critère `friedman_mse` ou `squared_error` n’impacte pratiquement pas la performance du modèle**.  \n",
    "Que ce soit en termes de **score OOB** ou de **temps d'entraînement**, les deux critères mènent aux **mêmes choix optimaux d'hyperparamètres**, avec des performances quasi-identiques.  \n",
    "Cela montre que, dans le cas de la forêt aléatoire, **le critère de construction locale des arbres influence peu la qualité globale du modèle**.\n",
    "\n",
    "\n",
    "$\\rightarrow$ **Influence de `max_features`**\n",
    "\n",
    "Comme nous l'avions observé lors de la modélisation sous R, **plus la proportion de variables sélectionnées à chaque split est élevée, meilleure est la performance de la forêt**.  \n",
    "Ici, c'est avec `max_features = 0.9` que nous obtenons les meilleurs scores OOB.\n",
    "\n",
    "En proposant davantage de variables au moment de créer les divisions, chaque arbre a accès à plus d'information pour produire des splits efficaces, ce qui améliore la qualité globale de la forêt.\n",
    "\n",
    "\n",
    "\n",
    "$\\rightarrow$ **Influence de `ccp_alpha` (élagage)**\n",
    "\n",
    "L'élagage, contrôlé via le paramètre `ccp_alpha`, **semble avoir un effet négligeable sur la performance OOB**.\n",
    "\n",
    "Quelle que soit la valeur choisie (0.01, 0.1, 1.0, 10.0), l'OOB score reste quasiment stable.  \n",
    "Cela indique que **le modèle est naturellement robuste** et peu sensible au surapprentissage, même sans élagage agressif.\n",
    "\n",
    "Cela confirme l'intuition classique en forêt aléatoire : **l'overfitting n'est pas un problème majeur** grâce à l'agrégation de nombreux arbres faibles.\n",
    "\n",
    "\n",
    "$\\rightarrow$ **Performances extrêmes (meilleur modèle)**\n",
    "\n",
    "- Le **meilleur modèle** atteint un **OOB score** de **0.975666** et a nécessité **5.211 secondes** pour être entraîné.\n",
    "- Ce modèle utilise :\n",
    "  - `n_estimators = 500`\n",
    "  - `max_features = 1.0`\n",
    "  - `ccp_alpha = 1.0`\n",
    "  - `criterion = friedman_mse`\n",
    "\n",
    "\n",
    "$\\rightarrow$ **Trade-off performance/temps**\n",
    "\n",
    "Parmi les modèles ayant un OOB score > 0.974, **le plus rapide** a pris seulement **0.897 secondes** pour un OOB score de **0.974343** (`n_estimators=100`, `max_features=0.8`, `ccp_alpha=0.10`).\n",
    "\n",
    "Cela montre que **des modèles plus légers peuvent offrir des performances presque équivalentes** tout en étant **beaucoup plus rapides** à entraîner.\n",
    "\n",
    "\n",
    "$\\rightarrow$ **Détail des modèles extrêmes**\n",
    "\n",
    "- **Top 10 modèles les plus longs à entraîner** (extraits du tableau) : majoritairement avec `n_estimators = 500`.\n",
    "- **Top 10 modèles les plus rapides** : configurations avec `n_estimators = 100` et `max_features` entre 0.8 et 1.0.\n",
    "\n",
    "Cela est cohérent avec l'idée que **plus le nombre d'arbres est élevé, plus le temps d'entraînement augmente**.\n",
    "\n",
    "--- \n",
    "\n",
    "**Conclusion** :\n",
    "\n",
    "Dans l'ensemble, nous constatons que :\n",
    "- **Un `max_features` élevé** permet d'améliorer significativement la performance du modèle.\n",
    "- **Le paramètre `ccp_alpha` (élagage) impacte très peu la qualité de la forêt**.\n",
    "- **Réduire `n_estimators`** permet **d’accélérer considérablement** l'entraînement sans perte substantielle de performance.\n",
    "- **La forêt aléatoire reste robuste** face au surapprentissage, même avec des arbres profonds et peu élagués.\n",
    "\n",
    "  \n",
    "Après avoir validé ces résultats, nous allons désormais nous intéresser à **l’importance des variables**, afin d’identifier les facteurs les plus influents dans la prédiction des calories, comme nous l'avions fait sous R.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Importance des variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the best random forest model \n",
    "\n",
    "best_rf_reg_cal = RandomForestRegressor(random_state=randomseed, n_estimators=500, max_features=0.9, ccp_alpha=0.01, criterion='friedman_mse', oob_score=True)\n",
    "best_rf_reg_cal.fit(X_train_calories_dummy, y_train_calories)\n",
    "\n",
    "# extract variable importance\n",
    "importances = best_rf_reg_cal.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = X_train_calories_dummy.columns[indices]\n",
    "importances = importances[indices]\n",
    "importances_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "importances_df['Cumulative Importance'] = importances_df['Importance'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(importances_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    data=importances_df,\n",
    "    palette='cool',\n",
    ")\n",
    "plt.title(\"Variable Importance from Random Forest\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : À partir du modèle de forêt aléatoire optimal entraîné sous `scikit-learn`, nous avons extrait l'importance des variables basée sur la réduction de l'impureté cumulée (Gini importance). \n",
    "\n",
    "- Le prédicateur `Session_Duration (hours)` domine, expliquant 73.67% de la variance, ce qui est intuitif puisqu'une **session plus longue** implique mécaniquement **une dépense énergétique plus élevée**.\n",
    "- Il est suivi par `Avg_BPM`, qui contribue à 10.56% de la variance, ce qui est également logique car un rythme cardiaque lors d'une séane de sport plus élevé est souvent associé à une **dépense calorique accrue**.\n",
    "- Enfin, `SFat_Percentage`, `Experience_Level` et `Age` ont des contributions faibles, mais permettent de capter des interactions intéressantes et améliorent la performance globale du modèle.\n",
    "\n",
    "On observe ainsi que 5 variables expliquent à elles seules plus de **97 % de l'importance totale du modèle**.\n",
    "\n",
    "En revanche, sous R, les variables `Session_Duration (hours)` et `Avg_BPM` étaient les seules à ressortir comme les plus importantes, tandis que toutes les autres variables avaient une importance très faible. Ainsi, on peut déduire que `scikit-learn` ne construit pas les forêts aléatoires de la même manière que `caret` sous R.\n",
    "\n",
    "Nous allons maintenant nous intéresser à un autre algorithme d'arbres de décision, le **boosting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "Gradient Boosting & XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Définir le nombre de folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=randomseed)\n",
    "\n",
    "# Stocker les scores et temps\n",
    "r2_scores_gb = []\n",
    "mse_scores_gb = []\n",
    "times_gb = []\n",
    "\n",
    "r2_scores_xgb = []\n",
    "mse_scores_xgb = []\n",
    "times_xgb = []\n",
    "\n",
    "# Boucle sur les folds\n",
    "for train_index, val_index in kf.split(X_train_calories):\n",
    "    X_train_fold, X_val_fold = X_train_calories.iloc[train_index], X_train_calories.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_calories.iloc[train_index], y_train_calories.iloc[val_index]\n",
    "    \n",
    "    # Dummifier pour Gradient Boosting (pas pour XGBoost car enable_categorical=True)\n",
    "    X_train_fold_dummies = pd.get_dummies(X_train_fold, columns=['Gender', 'Workout_Type'], drop_first=True)\n",
    "    X_val_fold_dummies = pd.get_dummies(X_val_fold, columns=['Gender', 'Workout_Type'], drop_first=True)\n",
    "    \n",
    "    ## 1. Gradient Boosting\n",
    "    start_time = time.time()\n",
    "    gb_reg = GradientBoostingRegressor(random_state=randomseed)\n",
    "    gb_reg.fit(X_train_fold_dummies, y_train_fold)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    y_pred_gb = gb_reg.predict(X_val_fold_dummies)\n",
    "    \n",
    "    r2_scores_gb.append(r2_score(y_val_fold, y_pred_gb))\n",
    "    mse_scores_gb.append(mean_squared_error(y_val_fold, y_pred_gb))\n",
    "    times_gb.append(elapsed_time)\n",
    "    \n",
    "    ## 2. XGBoost\n",
    "    start_time = time.time()\n",
    "    xgb_reg = XGBRegressor(random_state=randomseed, enable_categorical=True)\n",
    "    xgb_reg.fit(X_train_fold, y_train_fold)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    y_pred_xgb = xgb_reg.predict(X_val_fold)\n",
    "    \n",
    "    r2_scores_xgb.append(r2_score(y_val_fold, y_pred_xgb))\n",
    "    mse_scores_xgb.append(mean_squared_error(y_val_fold, y_pred_xgb))\n",
    "    times_xgb.append(elapsed_time)\n",
    "\n",
    "# Résultats finaux\n",
    "print(f\"Gradient Boosting R² moyen (CV) : {np.mean(r2_scores_gb):.4f} ± {np.std(r2_scores_gb):.4f}\")\n",
    "print(f\"Gradient Boosting MSE moyen (CV) : {np.mean(mse_scores_gb):.2f} ± {np.std(mse_scores_gb):.2f}\")\n",
    "print(f\"Gradient Boosting Temps moyen d'entraînement (par fold) : {np.mean(times_gb):.2f} sec\")\n",
    "\n",
    "print(f\"\\nXGBoost R² moyen (CV) : {np.mean(r2_scores_xgb):.4f} ± {np.std(r2_scores_xgb):.4f}\")\n",
    "print(f\"XGBoost MSE moyen (CV) : {np.mean(mse_scores_xgb):.2f} ± {np.std(mse_scores_xgb):.2f}\")\n",
    "print(f\"XGBoost Temps moyen d'entraînement (par fold) : {np.mean(times_xgb):.2f} sec\")\n",
    "\n",
    "# Performance sur le test final\n",
    "print(f\"\\nGradient Boosting R² sur l'ensemble de test : {r2_score(y_test_calories, gb_reg.predict(X_test_calories_dummy)):.4f}\")\n",
    "print(f\"Gradient Boosting MSE sur l'ensemble de test : {mean_squared_error(y_test_calories, gb_reg.predict(X_test_calories_dummy)):.2f}\")\n",
    "\n",
    "print(f\"XGBoost R² sur l'ensemble de test : {r2_score(y_test_calories, xgb_reg.predict(X_test_calories)):.4f}\")\n",
    "print(f\"XGBoost MSE sur l'ensemble de test : {mean_squared_error(y_test_calories, xgb_reg.predict(X_test_calories)):.2f}\")\n",
    "\n",
    "# Comparaison avec Random Forest\n",
    "\n",
    "print(f\"\\nRandom Forest R² sur l'ensemble de test : {r2_score(y_test_calories, best_rf_reg_cal.predict(X_test_calories_dummy)):.4f}\")\n",
    "print(f\"Random Forest MSE sur l'ensemble de test : {mean_squared_error(y_test_calories, best_rf_reg_cal.predict(X_test_calories_dummy)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** \n",
    "\n",
    "Les modèles de Gradient Boosting et de XGBoost présentent **d'excellentes performances** sans ajustement particulier des hyperparamètres.  \n",
    "\n",
    "À l'issue de la validation croisée 5-folds :\n",
    "- Le Gradient Boosting standard atteint un **R² moyen de 0.9937 ± 0.0014** et un **MSE moyen de 451.17 ± 69.83**,\n",
    "- Le modèle XGBoost atteint un **R² moyen de 0.9822 ± 0.0047** et un **MSE moyen de 1269.52 ± 255.84**.\n",
    "\n",
    "Les performances sur l'ensemble de test confirment cette excellente capacité de généralisation :\n",
    "- Le Gradient Boosting obtient un **R² de 0.9903** et un **MSE de 755.82**,\n",
    "- Le XGBoost obtient un **R² de 0.9824** et un **MSE de 1377.15**.\n",
    "\n",
    "On constate ainsi que **les deux modèles généralisent très bien**, sans réel phénomène de surapprentissage.\n",
    "\n",
    "En termes de coût computationnel, **les deux algorithmes sont très rapides à entraîner**, avec des temps moyens d'entraînement par fold d'environ **0.27 seconde pour Gradient Boosting** et **0.32 seconde pour XGBoost**.\n",
    "\n",
    "Comparativement, le modèle Random Forest, précédemment optimisé, obtient un **R² de 0.9768** et un **MSE de 1812.48**, tout en nécessitant un **temps d'entraînement beaucoup plus important** (~5.2 secondes).\n",
    "\n",
    "Ces résultats confirment que **les méthodes de boosting surpassent les forêts aléatoires** à la fois en termes de performance prédictive et d'efficacité computationnelle.\n",
    "\n",
    "Compte tenu de **ces résultats très satisfaisants**, notamment pour le Gradient Boosting, nous limiterons notre analyse aux modèles actuels sans procéder à une optimisation poussée de XGBoost.\n",
    "Toutefois, dans une démarche d'optimisation avancée, une recherche d'hyperparamètres sur XGBoost pourrait encore permettre d'améliorer ses performances.\n",
    "\n",
    "Dans ce contexte, nous allons désormais nous concentrer sur **l'interprétation de l'importance des variables**.\n",
    "\n",
    "#### **Importance des variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_gb_df = pd.DataFrame({'Feature': X_train_calories_dummy.columns, 'Importance': gb_reg.feature_importances_})\n",
    "importances_xgb_df = pd.DataFrame({'Feature': X_train_calories.columns, 'Importance': xgb_reg.feature_importances_})\n",
    "\n",
    "# Trier pour plus de lisibilité\n",
    "importances_gb_df = importances_gb_df.sort_values('Importance', ascending=False)\n",
    "importances_xgb_df = importances_xgb_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Tracer\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot pour Gradient Boosting\n",
    "sns.barplot(\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    data=importances_gb_df,\n",
    "    palette='cool',\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Variable Importance - Gradient Boosting\")\n",
    "axes[0].set_xlabel(\"Importance\")\n",
    "axes[0].set_ylabel(\"Feature\")\n",
    "\n",
    "# Plot pour XGBoost\n",
    "sns.barplot(\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    data=importances_xgb_df,\n",
    "    palette='cool',\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Variable Importance - XGBoost\")\n",
    "axes[1].set_xlabel(\"Importance\")\n",
    "axes[1].set_ylabel(\"\")  # Pas besoin de répéter \"Feature\" à droite\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que Gradient Boosting et XGBoost obtiennent des performances très proches en termes de R², une analyse de l'importance des variables révèle des différences notables dans les contributions fines.\n",
    "\n",
    "Dans les deux modèles, `Session_Duration (hours)` et `Avg_BPM` dominent largement la prédiction, ce qui est cohérent avec les résultats précédents observés sous forêts aléatoires et en R.\n",
    "\n",
    "Toutefois, lorsque l'on s'intéresse aux variables secondaires, **les importances relatives divergent** :\n",
    "- Gradient Boosting répartit l'importance restante entre les variables `Age`, `SFat_Percentage` et `Gender_Male` alors que `Experience_Level` est inexistant dans le modèle.\n",
    "- XGBoost attribue une importance non négligeable directement à `Gender` en le mettant au même niveau que `Avg_BPM`, tandis que `Age` et `SFat_Percentage` restent marginaux.\n",
    "\n",
    "Ces différences s'expliquent par :\n",
    "- **La nature des modèles** : XGBoost, utilisant du boosting plus régularisé, capte parfois des combinaisons d'interactions que Gradient Boosting classique ne priorise pas aussi fortement.\n",
    "- **La manière de calculer l’importance** : Gradient Boosting utilise la réduction moyenne d'impureté, alors que XGBoost utilise une mesure fondée sur le gain moyen de splits (avec régularisation intégrée).\n",
    "\n",
    "**Conclusion** : malgré des performances globales similaires, les deux méthodes peuvent exploiter **différentes structures locales dans les données**, ce qui peut être précieux en cas de recherche d'interprétabilité avancée.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_train_calories_scale_dummy = pd.get_dummies(X_train_calories_scale, columns=['Gender', 'Workout_Type'], drop_first=True)\n",
    "X_test_calories_scale_dummy = pd.get_dummies(X_test_calories_scale, columns=['Gender', 'Workout_Type'], drop_first=True)\n",
    "\n",
    "# Define the MLP Regressor\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', \n",
    "                             max_iter=500, random_state=randomseed)\n",
    "\n",
    "# Train the model on the training data\n",
    "mlp_regressor.fit(X_train_calories_scale_dummy, y_train_calories)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred_mlp = mlp_regressor.predict(X_test_calories_scale_dummy)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_test_mlp = mean_squared_error(y_test_calories, y_test_pred_mlp)\n",
    "r2_test_mlp = r2_score(y_test_calories, y_test_pred_mlp)\n",
    "\n",
    "print(\"MLP Regressor - MSE on test set: \", mse_test_mlp)\n",
    "print(\"MLP Regressor - R2 on test set: \", r2_test_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la grille d'hyperparamètres\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (150, 100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Configurer le GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=MLPRegressor(max_iter=500, random_state=randomseed),\n",
    "    param_grid=param_grid,\n",
    "    scoring='r2',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Effectuer la recherche sur les données d'entraînement\n",
    "grid_search.fit(X_train_calories_scale_dummy, y_train_calories)\n",
    "\n",
    "# Afficher les meilleurs paramètres et le score correspondant\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "print(\"Meilleur score R² :\", grid_search.best_score_)\n",
    "\n",
    "# Évaluer le modèle optimal sur l'ensemble de test\n",
    "best_mlp = grid_search.best_estimator_\n",
    "y_test_pred_best_mlp = best_mlp.predict(X_test_calories_scale_dummy)\n",
    "mse_test_best_mlp = mean_squared_error(y_test_calories, y_test_pred_best_mlp)\n",
    "r2_test_best_mlp = r2_score(y_test_calories, y_test_pred_best_mlp)\n",
    "\n",
    "print(\"MSE sur l'ensemble de test :\", mse_test_best_mlp)\n",
    "print(\"R² sur l'ensemble de test :\", r2_test_best_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Mesurer temps d'entraînement pour le meilleur modèle\n",
    "start_time = time.time()\n",
    "best_mlp.fit(X_train_calories_scale_dummy, y_train_calories)\n",
    "train_time_mlp = time.time() - start_time\n",
    "\n",
    "print(f\"Temps d'entraînement du meilleur MLP : {train_time_mlp:.2f} secondes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : Le meilleur modèle de réseau de neurones (MLP) a été entraîné via **GridSearchCV** avec une architecture de 3 couches cachées, utilisant la **fonction d'activation ReLU** et **l'optimiseur Adam**. Il obtient un **R² généralisé de 0.9728** et un **R² de 0.9845** sur l'ensemble de test, avec un **MSE de 1212.49**.\n",
    "\n",
    "Les meilleurs hyperparamètres sélectionnés sont :\n",
    "- Architecture : **(150, 100, 50)** (trois couches cachées)\n",
    "- Fonction d'activation : **ReLU**\n",
    "- Méthode d'optimisation : **Adam**\n",
    "- Apprentissage : **learning rate constant**\n",
    "- Régularisation (alpha) : **0.001**\n",
    "\n",
    "En termes de performance pure, le réseau de neurones optimisé se situe juste en-dessous des modèles de **Gradient Boosting** (meilleur modèle avec R² généralisé ≈ 0.9903) **et XGBoost** (R² généralisé ≈ 0.9824), mais semble légèrement mieux généraliser que le modèle XGBoost (bien que ce dernier n'ait pas été optimisé) en termes de MSE (1212.49 pour le MPL contre 1377.15 pour XGBoost).\n",
    "\n",
    "Le réseau de neurones a su **apprendre efficacement**, bien son **temps d'entraînement soit beaucoup plus important** par rapport aux modèles de ce niveau de performances (30 fois plus lent).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation finale (comparaison des modèles)\n",
    "\n",
    "\n",
    "L'ensemble des modèles évalués présente des performances très solides sur la prédiction des calories dépensées :\n",
    "\n",
    "| Modèle             | R² Test  | MSE Test | Temps d'entraînement |\n",
    "|:-------------------|:--------:|:--------:|:--------------------:|\n",
    "| Gradient Boosting   | 0.9903   | 755.82   | ~0.21 sec par fold    |\n",
    "| MLP (réseau de neurones) | 0.9845   | 1212.49  | ~6.7 sec (mesuré)        |\n",
    "| XGBoost             | 0.9824   | 1377.15  | ~0.14 sec par fold    |\n",
    "| Random Forest       | 0.9768   | 1812.48  | 5.2 sec (complet)     |\n",
    "\n",
    "Le **Gradient Boosting** conserve une légère avance en termes de précision et d'erreur quadratique moyenne.  \n",
    "Le **réseau de neurones** propose une alternative très compétitive, atteignant un niveau de performance intermédiaire entre Gradient Boosting et XGBoost.  \n",
    "Le **temps d'entraînement** du MLP reste parfaitement acceptable, comparable à celui du Gradient Boosting.\n",
    "\n",
    "Enfin, **XGBoost**, bien que légèrement en retrait sans tuning spécifique, surpasse malgré tout la **forêt aléatoire** en termes de précision et de vitesse.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion générale** :\n",
    "\n",
    "> En résumé, les modèles de boosting et de réseaux de neurones surpassent les forêts aléatoires en termes de performance et d'efficacité.  \n",
    "> Le Gradient Boosting apparaît comme le modèle le plus performant, tandis que le réseau de neurones constitue une alternative compétitive et rapide.  \n",
    "> Tous les modèles sélectionnés généralisent correctement, confirmant la qualité du jeu de données et la robustesse des méthodes employées.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **Comparaison synthétique des modèles de prédiction des calories brûlées**  \n",
    "Voici une analyse comparative des performances, avantages et limites de chaque méthode testée :\n",
    "\n",
    "\n",
    "### **Tableau Comparatif Synthétique des Modèles**\n",
    "\n",
    "| Modèle                     | R² Test    | MSE Test  | Temps d'entraînement (s) | Variables non nulles | Interprétabilité | Flexibilité (Non-linéarité) | Commentaire                                                                 |\n",
    "|----------------------------|------------|-----------|--------------------------|----------------------|-------------------|-----------------------------|------------------------------------------------------------------------------|\n",
    "| **Gradient Boosting**       | **0.9903** | **756**   | ~0.21/fold              | N/A                  | Modérée          | Élevée                      | Performances élevées en R² et MSE, temps rapide.                            |\n",
    "| **Lasso Quadratique**       | 0.993      | 542       | 0.012                   | 18                   | Haute            | Modérée (interactions)      | Meilleures performances grâce aux interactions non linéaires.               |\n",
    "| **SVR (noyau RBF)**         | 0.992      | 637       | 0.04                    | N/A                  | Faible           | Très élevée                 | Flexible mais peu interprétable.                                            |\n",
    "| **XGBoost**                 | 0.9824     | 1,377     | ~0.14/fold              | N/A                  | Modérée          | Élevée                      | Rapide et performant pour des données complexes.                            |\n",
    "| **Réseau de neurones (MLP)**| 0.9845     | 1,212     | 7.7                     | N/A                  | Faible           | Élevée                      | Complexe, temps d'entraînement élevé.                                       |\n",
    "| **Forêt aléatoire**         | 0.9768     | 1,812     | 5.2                     | N/A                  | Modérée          | Modérée                     | Équilibre entre performance et interprétabilité.                            |\n",
    "| **Régression Lasso (λ_min)**| 0.979      | 1,638     | 0.007                   | 12                   | Haute            | Aucune (linéaire)           | Performances optimales avec 12 variables.                                   |\n",
    "| **Régression Lasso (λ_1se)**| 0.979      | 1,764.87  | 0.004                   | 5                    | Haute            | Aucune (linéaire)           | Simplifié (5 variables), idéal pour l'interprétation.                       |\n",
    "| **Régression Ridge**        | 0.9787     | 1,661.23  | 1.67                    | Toutes               | Haute            | Aucune (linéaire)           | Régularisation L2 légèrement meilleure que la régression linéaire.          |\n",
    "| **Arbre de décision**       | 0.9425     | 4,484     | <1                      | N/A                  | Haute            | Modérée                     | Simple et rapide, mais performances limitées.                               |\n",
    "\n",
    "---\n",
    "\n",
    "avec\n",
    "\n",
    "1. **Temps d'entraînement** : \n",
    "   - `~0.21/fold` ou `~0.14/fold` : Temps moyen par fold en validation croisée.\n",
    "   - Autres valeurs : Temps total en secondes.\n",
    "2. **Variables non nulles** : Applicable uniquement aux modèles Lasso/Ridge.\n",
    "3. **Interprétabilité** :\n",
    "   - *Haute* : Modèles linéaires ou structure simple (ex: Lasso, Arbre).\n",
    "   - *Modérée* : Modèles complexes mais partiellement interprétables (ex: Forêt).\n",
    "   - *Faible* : Modèles \"boîte noire\" (ex: SVR, MLP).\n",
    "4. **Flexibilité** : Capacité à modéliser des relations non linéaires.\n",
    "#### **Analyse par méthode**  \n",
    "1. **Gradient Boosting**  \n",
    "   - **Avantages** : Meilleure performance globale (R² ≈ 0.99, MSE ≈ 756), rapidité, capture de relations non linéaires complexes.  \n",
    "   - **Limites** : Interprétabilité modérée (importance des variables mais pas des interactions précises).  \n",
    "   - **Cas d’usage** : Solution par défaut pour maximiser la précision sans contrainte de temps.  \n",
    "\n",
    "2. **Lasso Quadratique (interactions)**  \n",
    "   - **Avantages** : Performance proche du Gradient Boosting (MSE ≈ 571) avec une **interprétabilité élevée** (coefficients explicites).  \n",
    "   - **Limites** : Flexibilité limitée aux interactions polynomiales (degré 3).  \n",
    "   - **Cas d’usage** : Modèle équilibré pour expliquer des synergies entre variables (ex : âge × BPM).  \n",
    "\n",
    "3. **SVR (noyau RBF)**  \n",
    "   - **Avantages** : Flexibilité maximale pour capturer des motifs complexes (R² ≈ 0.992).  \n",
    "   - **Limites** : Boîte noire, temps d’optimisation long, difficile à interpréter.  \n",
    "   - **Cas d’usage** : Données hautement non linéaires où l’interprétation est secondaire.  \n",
    "\n",
    "4. **XGBoost**  \n",
    "   - **Avantages** : Rapidité et performance solide (R² ≈ 0.98), régularisation intégrée.  \n",
    "   - **Limites** : Légèrement moins précis que le Gradient Boosting standard.  \n",
    "   - **Cas d’usage** : Grands jeux de données nécessitant rapidité et parallélisation.  \n",
    "\n",
    "5. **Réseau de neurones (MLP)**  \n",
    "   - **Avantages** : Performance compétitive (R² ≈ 0.98), adapté aux patterns complexes.  \n",
    "   - **Limites** : Temps d’entraînement élevé, interprétabilité très faible.  \n",
    "   - **Cas d’usage** : Alternative aux SVR/boosting si l’infrastructure le permet.  \n",
    "\n",
    "6. **Forêt aléatoire**  \n",
    "   - **Avantages** : Robustesse, interprétabilité modérée (importance des variables).  \n",
    "   - **Limites** : Performance inférieure aux modèles de boosting, temps d’entraînement long.  \n",
    "   - **Cas d’usage** : Données bruyantes, besoin de stabilité sans optimisation fine.  \n",
    "\n",
    "7. **Modèles linéaires (Lasso/Ridge)**  \n",
    "   - **Avantages** : Interprétabilité maximale, rapidité.  \n",
    "   - **Limites** : Incapables de capturer des non-linéarités (MSE > 1,600).  \n",
    "   - **Cas d’usage** : Analyses exploratoires ou contraintes de simplicité.  \n",
    "\n",
    "8. **Arbre de décision**  \n",
    "   - **Avantages** : Interprétabilité haute, règles claires.  \n",
    "   - **Limites** : Surapprentissage marqué (MSE ≈ 4,484), performance faible.  \n",
    "   - **Cas d’usage** : Visualisation pédagogique, pas de déploiement en production.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Recommandations finales**  \n",
    "- **Pour la précision** : **Gradient Boosting** ou **Lasso Quadratique** (selon le besoin d’interprétabilité).  \n",
    "- **Pour la vitesse** : **XGBoost** ou **Lasso Quadratique**.  \n",
    "- **Pour l’interprétabilité** : **Lasso Quadratique** (interactions) ou **Régression Lasso** (modèle linéaire).  \n",
    "- **Pour les données non linéaires complexes** : **SVR (RBF)** ou **Réseau de neurones**.  \n",
    "\n",
    "**Conclusion** : Le choix dépend des priorités :  \n",
    "- Le **Gradient Boosting** et le **Lasso Quadratique** se démarquent comme les meilleurs compromis performance-interprétabilité.  \n",
    "- Les **modèles linéaires** restent utiles pour des insights rapides, mais sont limités par la nature non linéaire des données.  \n",
    "- Les **arbres (boosting/forêts)** et **SVR** sont à privilégier si la flexibilité prime sur l’explicabilité."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
