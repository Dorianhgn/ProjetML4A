{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Chargement des librairies nécessaires\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(gridExtra)\n",
    "library(GGally)\n",
    "library(plotly)\n",
    "library(corrplot)\n",
    "library(reshape2)\n",
    "library(FactoMineR) \n",
    "library(factoextra)\n",
    "library(glmnet) \n",
    "library(ggfortify)\n",
    "library(pROC)\n",
    "library(ROCR)\n",
    "library(repr)\n",
    "library(caret)\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "set.seed(1234)\n",
    "\n",
    "## GRAPH SETTINGS ##\n",
    "# Save original parameters (optional)\n",
    "original_par <- par(no.readonly = TRUE)\n",
    "\n",
    "# Set global scaling factors (1.5x default size)\n",
    "par(\n",
    "  cex.lab = 1.5,   # Axis labels\n",
    "  cex.axis = 1.5,  # Axis text (tick labels)\n",
    "  cex.main = 1.5,  # Main title\n",
    "  cex.sub = 1.5    # Subtitle\n",
    ")\n",
    "\n",
    "# Define a custom theme with larger fonts\n",
    "custom_theme <- theme(\n",
    "  text = element_text(size = 16),            # Global text size\n",
    "  axis.title = element_text(size = 18),      # Axis labels\n",
    "  axis.text = element_text(size = 14),       # Axis tick labels\n",
    "  plot.title = element_text(size = 20),      # Main title\n",
    "  plot.subtitle = element_text(size = 16)    # Subtitle\n",
    ")\n",
    "\n",
    "# Apply the theme to all future plots\n",
    "theme_set(custom_theme)\n",
    "\n",
    "\n",
    "## DATA LOADING & PROCESSING ##\n",
    "# Load data\n",
    "path <- \"../../\" # modifier le nombre de ../ si nécessaire\n",
    "gym <- read.table(paste(path, \"gym_members_exercise_tracking.csv\", sep = \"\"),\n",
    "                    sep = \",\", header = TRUE)\n",
    "\n",
    "gym[,'Gender'] <- as.factor(gym[,'Gender'])\n",
    "gym[,'Workout_Type'] <- as.factor(gym[,'Workout_Type'])\n",
    "gym[,'Experience_Level'] <- as.factor(gym[,'Experience_Level'])\n",
    "gym[,'Workout_Frequency..days.week.'] <- as.factor(gym[,'Workout_Frequency..days.week.'])\n",
    "\n",
    "gym[, \"Weight..kg.\"] <- log(gym[,\"Weight..kg.\"])\n",
    "\n",
    "max_fat <- max(gym[,\"Fat_Percentage\"])\n",
    "gym[, \"Fat_Percentage\"] <- sqrt((max_fat + 1) - gym[,\"Fat_Percentage\"])\n",
    "\n",
    "# renome les variables Weight..kg. et BMI en LWeight et LBMI\n",
    "names(gym)[names(gym) == \"Weight..kg.\"] <- \"LWeight\"\n",
    "names(gym)[names(gym) == \"Fat_Percentage\"] <- \"SFat_Percentage\"\n",
    "\n",
    "gym <- gym %>% select(-c(BMI))\n",
    "\n",
    "# divide data into training and testing sets for experience level\n",
    "trainIndex <- createDataPartition(gym$Experience_Level, p = .8, \n",
    "                                  list = FALSE, \n",
    "                                  times = 1)\n",
    "gym_train <- gym[ trainIndex,]\n",
    "gym_test  <- gym[-trainIndex,]\n",
    "\n",
    "# Normalize the data\n",
    "gym_train_scaled = gym_train\n",
    "scaler <- scale(gym_train[,-c(2,10,13,14)])\n",
    "\n",
    "# Extract the center and scale attributes\n",
    "center <- attr(scaler, \"scaled:center\")\n",
    "scale <- attr(scaler, \"scaled:scale\")\n",
    "\n",
    "gym_train_scaled[,-c(2,10,13,14)] <- scale(gym_train[,-c(2,10,13,14)], center = center, scale = scale)\n",
    "\n",
    "gym_test_scaled = gym_test\n",
    "gym_test_scaled[,-c(2,10,13,14)] <- scale(gym_test[,-c(2,10,13,14)], center = center, scale = scale)\n",
    "\n",
    "\n",
    "cat(\"Data loaded and preprocessed\")\n",
    "\n",
    "\n",
    "## FUNCTION DEFINITIONS ##\n",
    "\n",
    "# Function to plot residuals\n",
    "# x: predicted values\n",
    "# y: residuals\n",
    "gplot.res <- function(x, y, titre = \"titre\"){\n",
    "    ggplot(data.frame(x=x, y=y),aes(x,y))+\n",
    "    geom_point(col = \"blue\")+#xlim(0, 250)+ylim(-155, 155)+\n",
    "    ylab(\"Résidus\")+ xlab(\"Valeurs prédites\")+\n",
    "    ggtitle(titre)+\n",
    "    geom_hline(yintercept = 0,col=\"green\")\n",
    "}\n",
    "\n",
    "# Function to plot ROC curve\n",
    "# model: model to evaluate\n",
    "# data: data to evaluate\n",
    "# title: title of the plot\n",
    "plot_roc <- function(model, data, title = \"ROC curve\"){\n",
    "    pred <- predict(model, data, type = \"response\")\n",
    "    roc <- roc(data$Experience_Level, pred)\n",
    "    auc <- round(auc(roc), 2)\n",
    "    plot(roc, main = title)\n",
    "    text(0.8, 0.2, paste(\"AUC = \", auc), cex = 1.5)\n",
    "}\n",
    "\n",
    "# Function that compute R2\n",
    "\n",
    "# compute_R2 <- function(model, newdata = NA){\n",
    "#   if newdata == NA{\n",
    "#     residuals <- predict(model)\n",
    "#       rss <- sum()\n",
    "#       tss <- \n",
    "# }\n",
    "#   res.tree.cal.cp_high.test <- predict(tree.reg.cal.cp_high, newdata = gym_test)\n",
    "#   mse_test_cal_cp_high <- mean((res.tree.cal.cp_high.test - gym_test[,\"Calories_Burned\"])^2)\n",
    "#   rss_cal_cp_high <- sum((res.tree.cal.cp_high.test - gym_test[,\"Calories_Burned\"])^2)\n",
    "#   tss_cal_cp_high <- sum((gym_test[,\"Calories_Burned\"] - mean(gym_test[,\"Calories_Burned\"]))^2)\n",
    "#   r2_test_cal_cp_high <- 1 - rss_cal_cp_high / tss_cal_cp_high\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(gym_train_scaled)\n",
    "summary(gym_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "reg.lm <- lm(Calories_Burned ~ ., data = gym_train_scaled)\n",
    "\n",
    "# Summary of the regression\n",
    "summary(reg.lm)\n",
    "\n",
    "# Extract the residuals\n",
    "sel.lm <- reg.lm$residuals\n",
    "fit.lm <- reg.lm$fitted.values\n",
    "\n",
    "# Plot the residuals\n",
    "gplot.res(fit.lm, sel.lm, \"Régression linéaire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# MSE of the model on the training and test set\n",
    "mse_train <- mean(sel.lm^2)\n",
    "mse_test <- mean((predict(reg.lm, gym_test_scaled) - gym_test_scaled$Calories_Burned)^2)\n",
    "\n",
    "cat(\"MSE on training set: \", mse_train, \"\\n\")\n",
    "cat(\"MSE on test set: \", mse_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : Giga trompette, on va rajouter des termes quadratiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "x.mat <- model.matrix(Calories_Burned ~ . -1, data = gym_train_scaled)\n",
    "y.vec <- gym_train_scaled$Calories_Burned\n",
    "\n",
    "head(x.mat)\n",
    "\n",
    "# Fit the lasso model\n",
    "reg.lasso <- glmnet(x.mat, y.vec, alpha = 1, nfolds = 10) # alpha = 1 for lasso\n",
    "\n",
    "# Plot the coefficients\n",
    "options(repr.plot.width=12, repr.plot.height=10)\n",
    "plot(reg.lasso, xvar = \"lambda\", label = TRUE)\n",
    "legend(\"topright\", \n",
    "       legend = paste(1:ncol(x.mat), \" - \", colnames(x.mat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "reg.lasso.cv <- cv.glmnet(x.mat, y.vec, alpha = 1, nfolds = 10)\n",
    "reg.lasso.cv\n",
    "autoplot(reg.lasso.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"Best lambda: \", round(reg.lasso.cv$lambda.min,5), \"\\t \\t\")\n",
    "cat(\"MSE for best lambda: \", round(reg.lasso.cv$cvm[which.min(reg.lasso.cv$cvm)],5), \"\\n\")\n",
    "cat(\"Best lambda 1se: \", round(reg.lasso.cv$lambda.1se,5), \"\\t\")\n",
    "cat(\"MSE for best lambda 1se: \", round(reg.lasso.cv$cvm[which.min(reg.lasso.cv$cvm)],5), \"\\n\")\n",
    "\n",
    "\n",
    "# Extract the best model\n",
    "coef(reg.lasso.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(reg.lasso, xvar = \"lambda\", label = TRUE)\n",
    "abline(v=log(reg.lasso.cv$lambda.1se),col=\"red\")\n",
    "abline(v=log(reg.lasso.cv$lambda.min),col=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extract fitted values and residuals\n",
    "fit.lasso.min <- predict(reg.lasso.cv, s = \"lambda.min\", newx = x.mat)\n",
    "res.lasso.min <- y.vec - fit.lasso.min\n",
    "\n",
    "fit.lasso.1se <- predict(reg.lasso.cv, s = \"lambda.1se\", newx = x.mat)\n",
    "res.lasso.1se <- y.vec - fit.lasso.1se\n",
    "\n",
    "# Plot the residuals\n",
    "options(repr.plot.width=12, repr.plot.height=12)\n",
    "p0 <- gplot.res(fit.lm, sel.lm, \"Régression linéaire\")\n",
    "p1 <- gplot.res(fit.lasso.min, res.lasso.min, \"Lasso - Best lambda\")\n",
    "p2 <- gplot.res(fit.lasso.1se, res.lasso.1se, \"Lasso - Best lambda 1se\")\n",
    "\n",
    "grid.arrange(p0, p1, p2, ncol = 1)\n",
    "rm(p0, p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle Quadratique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Quadratic model with lasso\n",
    "x.mat.quad <- model.matrix(Calories_Burned ~ .^2 -1, data = gym_train_scaled)\n",
    "reg.lasso.quad.cv <- cv.glmnet(x.mat.quad, y.vec, alpha = 1, nfolds = 10)\n",
    "reg.lasso.quad.cv\n",
    "# coef(reg.lasso.quad.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fit.lasso.quad.1se <- predict(reg.lasso.quad.cv, s = \"lambda.1se\", newx = x.mat.quad)\n",
    "res.lasso.quad.1se <- y.vec - fit.lasso.quad.1se\n",
    "\n",
    "# Plot the residuals\n",
    "options(repr.plot.width=12, repr.plot.height=12)\n",
    "p0 <- gplot.res(fit.lm, sel.lm, \"Régression linéaire\")\n",
    "p1 <- gplot.res(fit.lasso.1se, res.lasso.1se, \"Lasso - Best lambda 1se\")\n",
    "p2 <- gplot.res(fit.lasso.quad.1se, res.lasso.quad.1se, \"Lasso - Best lambda 1se - Quadratic\")\n",
    "\n",
    "grid.arrange(p0, p1, p2, ncol = 1)\n",
    "rm(p0, p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "\n",
    "# SVM for regression\n",
    "svm.reg0 <- svm(Calories_Burned ~ ., data = gym_train_scaled, cross = 5)\n",
    "summary(svm.reg0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "svm.reg.tune = tune.svm(Calories_Burned ~ ., data = gym_train_scaled, cost = c(1, 25, 50, 75, 100, 150, 200), \n",
    "    gamma = 10^seq(-4, -2, by = 0.5))\n",
    "plot(svm.reg.tune)\n",
    "svm.reg.tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "svm.reg.tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Best model\n",
    "svm.reg <- svm.reg.tune$best.model\n",
    "\n",
    "# Predictions\n",
    "pred.svm.reg <- predict(svm.reg, newdata=gym_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "cat(\"SVM Regression Model\\n\")\n",
    "cat(\"MSE on test set: \", mean((gym_test_scaled$Calories_Burned - pred.svm.reg)^2), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graphe des résidus\n",
    "fit.svm.reg = svm.reg$fitted\n",
    "res.svm.reg = fit.svm.reg - gym_train_scaled$Calories_Burned\n",
    "gplot.res(fit.svm.reg, res.svm.reg, \"SVM Regression Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART & Agregation\n",
    "### Regression Trees\n",
    "\n",
    "- Fit a decision tree regressor.\n",
    "- Prune the tree using cross-validation.\n",
    "- Plot: Decision tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fit a regression tree model\n",
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "\n",
    "# Fit a regression tree model for Calories_Burned\n",
    "tree.reg.cal <- rpart(Calories_Burned ~ ., data = gym_train, control=rpart.control(cp=0.0001))\n",
    "\n",
    "options(repr.plot.width=18, repr.plot.height=12)\n",
    "# Plot the tree\n",
    "rpart.plot(tree.reg.cal, extra = 101, type = 3, under = TRUE, cex = 0.8, tweak = 1)\n",
    "\n",
    "# summary(tree.reg.cal)\n",
    "\n",
    "# compute MSE and R2 on training and test sets\n",
    "mse_train <- mean((gym_train$Calories_Burned - predict(tree.reg.cal, gym_train))^2)\n",
    "mse_test <- mean((gym_test$Calories_Burned - predict(tree.reg.cal, gym_test))^2)\n",
    "r2_train <- 1 - mse_train / var(gym_train$Calories_Burned)\n",
    "r2_test <- 1 - mse_test / var(gym_test$Calories_Burned)\n",
    "cat(\"MSE on training set: \", mse_train, \"\\n\")\n",
    "cat(\"MSE on test set: \", mse_test, \"\\n\")\n",
    "cat(\"R2 on training set: \", r2_train, \"\\n\")\n",
    "cat(\"R2 on test set: \", r2_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : Nous avons initialement construit un arbre de régression avec un paramètre de complexité extrêmement faible (`cp = 0.0001`). Comme attendu, ce modèle présente une structure profondément ramifiée (58 feuilles), caractéristique d'un sur-apprentissage. Ce modèle présente une performance relativement bonne sur le jeu d’entraînement (R² = 0.966, MSE = 2613), mais un écart significatif entre l’erreur d’entraînement et de test (MSE_test = 4521) révèle un sur-apprentissage. Toutefois, le R² sur le test reste élevé (0.934), indiquant que le modèle capture une part substantielle de la variance explicative, malgré sa complexité excessive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=12, repr.plot.height=8)\n",
    "\n",
    "xmat = xpred.rpart(tree.reg.cal, xval = 10)\n",
    "\n",
    "CVerr<-apply((xmat-gym_train[,\"Calories_Burned\"])^2,2,sum)\n",
    "\n",
    "plotcp(tree.reg.cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(as.numeric(names(CVerr)), CVerr, type = \"b\", xlab = \"cp\", ylab = \"CV Error\", main = \"CV Error vs cp\", log = \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=18, repr.plot.height=12)\n",
    "as.numeric(attributes(which.min(CVerr))$names)\n",
    "tree.reg.cal <- rpart(Calories_Burned ~ ., data = gym_train, control=rpart.control(cp=as.numeric(attributes(which.min(CVerr))$names)))\n",
    "\n",
    "# Plot the tree\n",
    "rpart.plot(tree.reg.cal, extra = 101, type = 3, under = TRUE, cex = 0.8, tweak = 1)\n",
    "\n",
    "# display the number of nodes of the treee\n",
    "cat(\"Number of nodes: \", length(tree.reg.cal$frame$var), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : La validation croisée 10-fold a identifié une pénalité optimale inattendue (`cp ≈ 0.00015`), conduisant à une erreur de validation (MSE ≈ 4521) inférieure aux modèles moins complexes. Ce résultat paradoxal – où réduire `cp` améliore la performance en validation – pourrait s'expliquer par :\n",
    "- La présence d'interactions complexes dans les données, nécessitant une structure arborescente fine pour être capturées,\n",
    "- Un biais de sélection lié à l'échantillon, où le sur-apprentissage partiel reste généralisable.\n",
    "\n",
    "Le premier point est peu probable car le modèle de régression linéaire avec régularisation LASSO a déjà capturé la plupart des interactions significatives. Le second point est plus plausible, suggérant que le modèle a appris des motifs spécifiques à l'échantillon d'entraînement qui se généralisent bien à la validation croisée.\n",
    "\n",
    "Cependant, l'arbre résultant reste difficilement interprétable (115 nœuds), soulignant un compromis problématique entre performance et explicabilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# library(partykit)\n",
    "# plot(as.party(tree.reg.cal), type=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=18, repr.plot.height=15)\n",
    "\n",
    "fit.tree.cal=predict(tree.reg.cal)\n",
    "res.tree.cal=fit.tree.cal-gym_train[,\"Calories_Burned\"]\n",
    "p1 <- gplot.res(fit.tree.cal,res.tree.cal,\"residus de tree.reg.cal (cp~0.00015)\")\n",
    "\n",
    "fit.tree.cal.test=predict(tree.reg.cal, newdata=gym_test)\n",
    "res.tree.cal.test=fit.tree.cal.test-gym_test[,\"Calories_Burned\"]\n",
    "p2 <- gplot.res(fit.tree.cal.test,res.tree.cal.test,\"residus de tree.reg.cal.test (cp~0.00015)\")\n",
    "\n",
    "# Create a tree with lower complexity parameter (cp)\n",
    "tree.reg.cal.cp_high <- rpart(Calories_Burned ~ ., data = gym_train, control=rpart.control(cp=0.01))\n",
    "\n",
    "fit.tree.cal.cp_high=predict(tree.reg.cal.cp_high)\n",
    "res.tree.cal.cp_high=fit.tree.cal.cp_high-gym_train[,\"Calories_Burned\"]\n",
    "p3 <- gplot.res(fit.tree.cal.cp_high,res.tree.cal.cp_high,\"residus de tree.reg.cal.cp_high (cp=0.01)\")\n",
    "fit.tree.cal.cp_high.test=predict(tree.reg.cal.cp_high, newdata=gym_test)\n",
    "res.tree.cal.cp_high.test=fit.tree.cal.cp_high.test-gym_test[,\"Calories_Burned\"]\n",
    "p4 <- gplot.res(fit.tree.cal.cp_high.test,res.tree.cal.cp_high.test,\"residus de tree.reg.cal.cp_high.test (cp=0.01)\")\n",
    "\n",
    "grid.arrange(p1, p2, p3, p4, ncol = 2)\n",
    "rm(p1, p2, p3, p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate metrics for tree.reg.cal\n",
    "mse_train_cal <- mean(res.tree.cal^2)\n",
    "r2_train_cal <- 1 - mean(res.tree.cal^2) / var(gym_train[,\"Calories_Burned\"])\n",
    "\n",
    "res.tree.cal.test <- predict(tree.reg.cal, newdata = gym_test)\n",
    "mse_test_cal <- mean((res.tree.cal.test - gym_test[,\"Calories_Burned\"])^2)\n",
    "rss_cal <- sum((res.tree.cal.test - gym_test[,\"Calories_Burned\"])^2)\n",
    "tss_cal <- sum((gym_test[,\"Calories_Burned\"] - mean(gym_test[,\"Calories_Burned\"]))^2)\n",
    "r2_test_cal <- 1 - rss_cal / tss_cal\n",
    "\n",
    "# Calculate metrics for tree.reg.cal.cp_high\n",
    "mse_train_cal_cp_high <- mean(res.tree.cal.cp_high^2)\n",
    "r2_train_cal_cp_high <- 1 - mean(res.tree.cal.cp_high^2) / var(gym_train[,\"Calories_Burned\"])\n",
    "\n",
    "res.tree.cal.cp_high.test <- predict(tree.reg.cal.cp_high, newdata = gym_test)\n",
    "mse_test_cal_cp_high <- mean((res.tree.cal.cp_high.test - gym_test[,\"Calories_Burned\"])^2)\n",
    "rss_cal_cp_high <- sum((res.tree.cal.cp_high.test - gym_test[,\"Calories_Burned\"])^2)\n",
    "r2_test_cal_cp_high <- 1 - rss_cal_cp_high / tss_cal\n",
    "\n",
    "# Create a summary table\n",
    "results <- data.frame(\n",
    "    Model = c(\"tree.reg.cal\", \"tree.reg.cal.cp_high\"),\n",
    "    MSE_Train = c(mse_train_cal, mse_train_cal_cp_high),\n",
    "    MSE_Test = c(mse_test_cal, mse_test_cal_cp_high),\n",
    "    R2_Train = c(r2_train_cal, r2_train_cal_cp_high),\n",
    "    R2_Test = c(r2_test_cal, r2_test_cal_cp_high)\n",
    ")\n",
    "\n",
    "# Print the table\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : Le modèle complexe (`cp = 0.00015`) montre des résidus mieux centrés et moins dispersés que le modèle élagué (`cp = 0.01`), avec des métriques favorables (R²_test = 0.934 vs 0.853). Toutefois, ces résultats masquent deux risques critiques :\n",
    "1. Strucutre instable : Une légère perturbation des données pourrait altérer radicalement la structure et la hierarchie des nœuds,\n",
    "2. Robustesse incertaine : La performance pourrait se dégrader sur des jeux de données déséquilibrés ou non stationnaires.\n",
    "\n",
    "Pour lever ces doutes, une validation complémentaire par bootstrap (échantillonnage Monte Carlo) serait nécessaire afin d'étudier la variabilité des partitions de l'arbre.\n",
    "\n",
    "**Bilan** :\n",
    "Ces résultats paradoxaux – un modèle clairement surappris mais conservant un pouvoir prédictif élevé – suggère deux hypothèses : \n",
    "1. Signal fort dans les données : Les variables explicatives contiennent des relations structurelles robustes (linéaires ou non-linéaires), qui seraient généralisables même avec un arbre très complexe.  \n",
    "2. Limites du sur-apprentissage arborescent : Contrairement à d’autres méthodes (ex : réseaux de neurones), les arbres surappris peuvent rester partiellement interprétables et éviter un effondrement complet en généralisation. \n",
    "\n",
    "Néanmoins, la supériorité du modèle linéaire (R²_test = 0.98) remet en question la pertinence de la complexité de l'arbre. Si la relation sous-jacente est majoritairement linéaire, l’arbre introduit un biais de variance inutile. Cette observation plaide pour une analyse comparative approfondie entre modèles linéaires et non linéaires.\n",
    "\n",
    "Pour conclure, bien que l’arbre complexe ne soit pas optimal (sur-apprentissage avéré et performance inférieure au linéaire), sa robustesse relative en généralisation (R²_test = 0.93) souligne la présence de motifs prédictifs stables dans les données. Ce résultat justifie une exploration des méthodes hybrides (ex : forêts aléaires avec régularisation, XGBoost) pour concilier flexibilité non linéaire et stabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests and Boosting\n",
    "- Random forests with `mtry` and Brieman criterion\n",
    "- Regularization with Boosting\n",
    "- Using Bootsratp\n",
    "- **plot** feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rf.reg.cal <- randomForest(Calories_Burned ~ ., data = gym_train,\n",
    " xtest = gym_test[, -9], ytest = gym_test[, \"Calories_Burned\"],\n",
    " ntree=500,do.trace=50,importance=TRUE, keep.forest = TRUE)\n",
    "\n",
    "attributes(rf.reg.cal)\n",
    "\n",
    "cat(\"mtry = \", rf.reg.cal$mtry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\nOOB MSE train:\", mean(rf.reg.cal$mse))\n",
    "cat(\"\\nMSE test:\", mean(rf.reg.cal$test$mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Plot MSE OOB as a function of the number of trees\n",
    "options(repr.plot.width=12, repr.plot.height=8)\n",
    "plot(rf.reg.cal$mse, type = \"l\", col = \"blue\", lwd = 2,\n",
    "    xlab = \"Number of Trees\", ylab = \"MSE (OOB)\",\n",
    "    main = \"MSE (OOB) vs Number of Trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif des forets aléatoires est de réduire la variance des arbres tout en conservant leur pouvoir prédictif via le bagging, qui est une technique combinant bootstraping et agrégation d'arbres.\n",
    "\n",
    "**Paramètres à optimiser** : \n",
    "- `mtry`, le nombre de variables tirées aléatoirement à chaque split.\n",
    "    - **Empiriquement** il est choisi par `mtry ≈ p/3` en régression ou `p` est le nombre total de variables. Ici `p = 14` donc `mtry` vaut logiquement 4.\n",
    "    - L'optimisation du `mtry` va être réalisé avec la fonction tuneRF qui cherche en partant du `mtry = p/3 = 4` et va essayer avec un mtry plus petit ou plus grand selon comment varie l'erreur de généralisation Out-Of-Bag (OOB). Il s'arrête dès qu'une amélioration de cette erreur OOB est inférieure à 5% (par défaut).\n",
    "- `ntree`, le nombre d'arbre dans la forêt. Il varie de 100 à 500 et les gains sont marginaux au-delà."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimisation du `mtry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=12, repr.plot.height=8)\n",
    "\n",
    "rf.reg.cal.tune <- tuneRF(gym_train[,-9], gym_train[,9], ntreeTry = 100,\n",
    " improve = 0.01, trace = 50, doBest = TRUE, xtest = gym_test[, -9],\n",
    "  ytest = gym_test[, \"Calories_Burned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"mtry optimal = \", rf.reg.cal.tune$mtry, \"\\n\")\n",
    "\n",
    "res.rf.cal <- rf.reg.cal.tune$predicted\n",
    "r2.rf.cal.train <- 1 - mean(res.rf.cal^2) / tss_cal\n",
    "\n",
    "res.rf.cal.test <- rf.reg.cal.tune$test$predicted\n",
    "rss.rf.cal.test <- sum((res.rf.cal.test - gym_test[,\"Calories_Burned\"])^2)\n",
    "r2.rf.cal.test <- 1 - rss.rf.cal.test / tss_cal\n",
    "\n",
    "cat(\"R2 train :\", r2.rf.cal.train, \"\\n\")\n",
    "cat(\"R2 test :\", r2.rf.cal.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"OOB MSE train:\", mean(rf.reg.cal.tune$mse))\n",
    "cat(\"\\nMSE test:\", mean(rf.reg.cal.tune$test$mse))\n",
    "cat(\"\\nAmelioration de l'OOB MSE train:\", abs(mean(rf.reg.cal.tune$mse) - mean(rf.reg.cal$mse)), \"\\n\")\n",
    "cat(\"Amelioration du MSE test:\", abs(mean(rf.reg.cal.tune$test$mse) - mean(rf.reg.cal$test$mse)), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après optimisation du `mtry`, le R² train et test sont très bons et l'amélioration de l'erreur OOB et du MSE sur l'échantillon de test est significative.\n",
    "\n",
    "Le `mtry` optimal trouvé par l'algorithme est **13**. Or le nombre de prédicateurs dans notre jeu de données est 13. \n",
    "L'alogrithme a donc utilisé tous les prédicteurs pour construire chaque arbre. Cela pourraît indiquer que peu de prédicteurs sont réellement importants pour la prédiction. En effet, si chaque arbre de la forêt a besoin de comparer tous les prédicateurs, c'est qu'il doit sûrement choisir les mêmes à chaque fois, et ce peu importe l'échantillon boostrap choisi. Cela est à vérifier avec l'importance des variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fit.rf.cal.tune <- rf.reg.cal.tune$predicted\n",
    "res.rf.cal.tune <- fit.rf.cal.tune - gym_train[,\"Calories_Burned\"]\n",
    "gplot.res(fit.rf.cal.tune, res.rf.cal.tune, titre=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : Le graphique des résidus révèle une performance inégale du modèle selon l’intensité de la dépense calorique. Pour les valeurs modérées (400–1200 calories), les résidus sont centrés et faiblement dispersés ($\\pm 100$), attestant d’une prédiction fiable. En revanche, au-delà de 1200 calories, la dispersion des résidus s’accentue significativement, suggérant une difficulté à modéliser les comportements extrêmes. Cette limitation pourrait s’expliquer par la rareté des données pour des séances à dépense calorique ou des interactions non linéaires non capturées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(ggRandomForests)\n",
    "\n",
    "options(repr.plot.width=18, repr.plot.height=8)\n",
    "\n",
    "p1 <- plot(gg_vimp(rf.reg.cal), main = \"Importance des variables (mtry = 4)\")\n",
    "p2 <- plot(gg_vimp(rf.reg.cal.tune), main = \"Importance des variables (mtry = 13)\")\n",
    "\n",
    "grid.arrange(p1, p2, ncol = 2)\n",
    "rm(p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La comparaison des forêts avec `mtry=4` et `mtry=13` révèle que :\n",
    "- les prédicateurs `Session_Duration` et `Avg_BPM` sont si fortement liés à la variable cible qu'ils sont selectionnés systématiquement, même lorsque toutes les variables sont disponibles. Ce comportement rappelle les modèles linéaires (Ridge et Lasso) où seules ces variables sont retenues à forte régularisation.\n",
    "- `Experience_Level` et `SFat_Percentage` n’émergent qu’avec `mtry=4`, suggérant que leurs effets sont liés à des interactions locales.\n",
    "\n",
    "Le tuning de `mtry=13` simplifie l’interprétation en isolant deux les variables globales, mais la forêt perd en diversité structurelle (les arbres sont plus similaires). En revanche, elle gagne en stabilité prédictive, indiqué par un R²_test = 0.98 et R²_train = 0.92 et une amélioration significative de l'erreur OOB et du MSE sur l'échantillon de test.\n",
    "\n",
    "Nous allons desormais visualiser les effet marginaux de ces variables sur la prédiction du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(pdp)\n",
    "p1 <- partial(rf.reg.cal, pred.var = \"Session_Duration..hours.\", plot = TRUE, rug = TRUE, train=gym_train, type=\"regression\")\n",
    "p2 <- partial(rf.reg.cal, pred.var = \"Avg_BPM\", plot = TRUE, rug = TRUE, train=gym_train, type=\"regression\")\n",
    "p3 <- partial(rf.reg.cal, pred.var = \"SFat_Percentage\", plot = TRUE, rug = TRUE, train=gym_train, type=\"regression\")\n",
    "p4 <- partial(rf.reg.cal, pred.var = \"Experience_Level\", plot = TRUE, rug = TRUE, train=gym_train, type=\"auto\")\n",
    "\n",
    "options(repr.plot.width=14, repr.plot.height=10)\n",
    "main = \"Partial Dependence Plots (mtry = 4)\"\n",
    "grid.arrange(p1, p2, p3, p4, ncol = 2, top = main)\n",
    "rm(p1, p2, p3, p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation des effets marginaux pour `mtry=4`** :\n",
    "\n",
    "**Effet de `Session_Duration`** : La relation entre la durée de la session et la dépense calorique est positive, avec une pente décroissante. Cela suggère que les premières heures d'entraînement ont un rendement calorique élevé, mais au delà de 1h30 de séance, l'augmentation marginale de la dépense diminue avec le temps. Ce phénomène pourrait être dû à la fatigue ou à l'adaptation physiologique des individus à l'exercice prolongé.\n",
    "\n",
    "**Effet de `Avg_BPM`** : La frequence cardiaque semble moyenne doit dépasser un certain seuil pour maximiser la dépense énergitique (140-160 bpm). En revanche, on retrouve un léger **effet de plateau** au delà de 160 bpm, suggérant que la dépense calorique n'augmente plus significativement à des niveaux d'intensité cardiaque extrêmes. Cela pourrait être dû aux limites physiologiques du corps humain.\n",
    "\n",
    "**Effet de `Experience_Level`** : L'expérience des individus a un impact significatif sur la dépense calorique. Les débutants (niveau 1) et intermédiares (niveau 2) ont des dépenses caloriques similaires, mais les experts (niveau 3) semblent avoir une dépense calorique plus élevée. Cela pourrait s'expliquer par une meilleure efficacité de l'entraînement chez les individus expérimentés, qui brûlent plus de calories à un rythme similaire.\n",
    "\n",
    "**Effet de `SFat_Percentage`** : La transformation appliquée à `Fat_Percentage` (sqrt(max + 1 - x)) complexifie l’interprétation directe. Le pic observé à `SFATPercentage=4` pourrait correspondre à un taux de graisse corporelle optimal pour la dépense énergétique, mais une analyse avec la variable originale est nécessaire pour confirmer cette hypothèse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# recreate fat percentage\n",
    "gym_train[,\"Fat_Percentage\"] <- (max_fat + 1) - gym_train[,\"SFat_Percentage\"]^2\n",
    "gym_test[,\"Fat_Percentage\"] <- (max_fat + 1) - gym_test[,\"SFat_Percentage\"]^2\n",
    "\n",
    "rf.reg.cal.fat_percentage <- randomForest(Calories_Burned ~ ., data = gym_train[, -11],\n",
    " xtest = gym_test[, -c(9, 11)], ytest = gym_test[, \"Calories_Burned\"],\n",
    " ntree=500,importance=TRUE, keep.forest = TRUE)\n",
    "\n",
    "rf.reg.cal.fat_percentage.tune <- randomForest(Calories_Burned ~ ., data = gym_train[, -11],\n",
    " ntree=500, mtry=13,\n",
    " xtest = gym_test[, -c(9, 11)], ytest = gym_test[, \"Calories_Burned\"],\n",
    " importance=FALSE, keep.forest = TRUE)\n",
    "\n",
    "# Partial dependence plot for Fat_Percentage\n",
    "options(repr.plot.width=18, repr.plot.height=8)\n",
    "# partial(rf.reg.cal.fat_percentage, pred.var = \"Fat_Percentage\",   rug = TRUE, train=gym_train, type=\"regression\")\n",
    "p1<-plot(gg_vimp(rf.reg.cal.fat_percentage), main = \"Importance des variables (mtry = 4)\")\n",
    "p2<-plot(gg_vimp(rf.reg.cal.fat_percentage.tune), main = \"Importance des variables (mtry = 13)\")\n",
    "\n",
    "grid.arrange(p1, p2, ncol = 2)\n",
    "rm(p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : On retrouve bien les même niveaux d'importance de nos variables en ayant interchangé `SFat_Percentage` par `Fat_Percentage` dans le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=12, repr.plot.height=8)\n",
    "autoplot(partial(rf.reg.cal.fat_percentage, pred.var = \"Fat_Percentage\", rug = TRUE, train=gym_train[], type=\"regression\"),\n",
    "        main = \"Partial Dependence Plot for Fat_Percentage (mtry = 13)\")\n",
    "\n",
    "# delete Fat_Percentage\n",
    "gym_train <- gym_train %>% select(-c(Fat_Percentage))\n",
    "gym_test <- gym_test %>% select(-c(Fat_Percentage))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** :\n",
    "\n",
    "La transformation appliqué à SFat_Percentage inverse artificiellement son echelle :\n",
    "\n",
    "$$\n",
    "\\text{SFatPercentage} = \\sqrt{\\max(\\text{FatPercentage}) + 1 - \\text{FatPercentage}}\n",
    "$$\n",
    "\n",
    "Ainsi une valeur élevée de `SFat_Percentage` correspond à un faible taux de masse grasse et inversement.\n",
    "\n",
    "La forêt detecte une relation **non linéaire** entre le taux de masse grasse et la dépense calorique. On distingue deux groupes d'individus :\n",
    "\n",
    "- Ceux avec un taux de masse grasse compris entre 10 et 20%.\n",
    "- Ceux avec un taux de masse grasse compris entre 20 et 35%.\n",
    "\n",
    "Les individus entre 10 et 20% brûlent environ 100 calories de plus que ceux avec un taux de masse grasse entre 20 et 35%.\n",
    "\n",
    "Avant d'interpréter ce résultat, il faut observer que la foret avec un `mtry=13` n'a retenu que 2 variables : `Session_Duration` et `Avg_BPM`. Pour rappel, comme on a pu le voir dans l'analyse descriptive et lors de l'Analyse en Composante Principales, la variable `Fat_Percentage` est fortement négativement corrélée avec `Session_Duration`. Sur les graphiques des variables de l'ACP, on a pu observer que `Fat_Percentage` était projeté dans la même direction que `Session_Duration` et `Calories_Burned`. Ce qui montre la redondance entre ces variables pour prédire `Calories_Burned` et donc l'importance de `Session_Duration` pour expliquer la dépense calorique.\n",
    "\n",
    "**Bilan** : On avait pu déduire que les individus avec un faible taux de masse grasse sont ceux qui s'entraînent le plus longtemps et donc **qui ont la plus forte dépense calorique**. En revanche, les individus avec un taux de masse grasse élevé sont ceux qui s'entraînent le moins longtemps et donc **qui ont la plus faible dépense calorique**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rf.reg.cal.tuned <- randomForest(Calories_Burned ~ ., data = gym_train,\n",
    " ntree=100, mtry = 13, importance=TRUE, keep.forest = TRUE)\n",
    "\n",
    "p1 <- partial(rf.reg.cal.tuned, pred.var = \"Session_Duration..hours.\", plot = TRUE, rug = TRUE, train=gym_train, type=\"regression\")\n",
    "p2 <- partial(rf.reg.cal.tuned, pred.var = \"Avg_BPM\", plot = TRUE, rug = TRUE, train=gym_train, type=\"regression\")\n",
    "\n",
    "options(repr.plot.width=16, repr.plot.height=8)\n",
    "main = \"Partial Dependence Plots (mtry = 13)\"\n",
    "grid.arrange(p1, p2, ncol = 2, top = main)\n",
    "rm(p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation** : \n",
    "\n",
    "Le nombre de calories brulées par séance est linéarement lié à la durée de la séance, avec un delta significatif de ~1000 calories entre les séances de 30 minutes et celles de 2h. Pour ce qui est de la fréquence cardiaque moyenne de la séance, on observe la même relation que précedemment, avec un delta plus faible (~200 calories) entre les séances à 120 bpm et celles à 160 bpm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting\n",
    "Pour améliorer la performance du modèle, nous allons utiliser le boosting, qui consiste à ajuster les erreurs des arbres précédents en ajoutant de nouveaux arbres. Le boosting est particulièrement efficace pour réduire le biais et améliorer la précision des prédictions.\n",
    "\n",
    "##### Avec la librairie `gbm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(gbm)\n",
    "options(repr.plot.width=12, repr.plot.height=8)\n",
    "boost.reg.cal = gbm(Calories_Burned ~ ., data = gym_train, distribution = \"gaussian\", n.trees = 1000, \n",
    "    cv.folds = 10, n.minobsinnode = 5, shrinkage = 0.03, verbose = FALSE)\n",
    "# verbose à FALSE pour éviter trop de sorties\n",
    "plot(boost.reg.cal$cv.error, type = \"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "best.iter <- gbm.perf(boost.reg.cal, method=\"cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(gbm)\n",
    "library(dplyr)\n",
    "\n",
    "# Définir la grille d'hyperparamètres\n",
    "grid <- expand.grid(\n",
    "  n.trees = c(400, 800, 1000), # Nombre d'arbres\n",
    "  interaction.depth = c(1, 3, 5), # Profondeur max des arbres\n",
    "  shrinkage = c(0.01, 0.1), # learning rate\n",
    "  n.minobsinnode = c(10, 20) # Nombre minimum d'observations dans les nœuds terminaux\n",
    ")\n",
    "\n",
    "# Contrôle de validation croisée\n",
    "ctrl <- trainControl(method = \"cv\", number = 5)\n",
    "\n",
    "# Grid Search via caret::train\n",
    "set.seed(123)\n",
    "boost.reg.cal <- train(\n",
    "  Calories_Burned ~ .,\n",
    "  data = gym_train,\n",
    "  method = \"gbm\",\n",
    "  trControl = ctrl,\n",
    "  tuneGrid = grid,\n",
    "  verbose = FALSE\n",
    ")\n",
    "\n",
    "# Résultats\n",
    "print(boost.reg.cal)\n",
    "plot(boost.reg.cal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "best_result <- semi_join(boost.reg.cal$results, boost.reg.cal$bestTune, \n",
    "                         by = c(\"n.trees\", \"interaction.depth\", \"shrinkage\", \"n.minobsinnode\"))\n",
    "\n",
    "print(best_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# compute MSE and R2 on training and test sets\n",
    "mse_train <- mean((gym_train$Calories_Burned - predict(boost.reg.cal, gym_train))^2)\n",
    "mse_test <- mean((gym_test$Calories_Burned - predict(boost.reg.cal, gym_test))^2)\n",
    "r2_train <- 1 - mse_train / var(gym_train$Calories_Burned)\n",
    "r2_test <- 1 - mse_test / var(gym_test$Calories_Burned)\n",
    "# cat(\"MSE on training set: \", mse_train, \"\\n\")\n",
    "cat(\"MSE on test set: \", mse_test, \"\\n\")\n",
    "# cat(\"R2 on training set: \", r2_train, \"\\n\")\n",
    "cat(\"R2 on test set: \", r2_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation des resultats du Boosting (GBM)** :\n",
    "\n",
    "**Performance Exceptionnelle** :  \n",
    "- **R²_test = 0.997** et **MSE_test = 213** : Le modèle explique **99.7%** de la variance des calories brûlées, avec une erreur moyenne de **±14.6 kcal** (√MSE).  \n",
    "- **Supériorité Claire** : Il surpasse largement la forêt aléatoire (`R²_test=0.978`, `MSE_test=1519`), grâce à sa capacité à **optimiser séquentiellement les erreurs résiduelles** et à capturer des **interactions complexes**.  \n",
    "\n",
    "**Explication de cette performance** :  \n",
    "1. **Hyperparamètres Optimaux** :  \n",
    "   - **`shrinkage=0.1`** (taux d’apprentissage bas) $\\rightarrow$ Apprentissage stable et précis.  \n",
    "   - **`interaction.depth=3`** $\\rightarrow$ Abres de profondeur 3, permettant de capturer des interactions complexes sans surajuster.\n",
    "   - **`n.trees=1000`** $\\rightarrow$ Suffisant pour converger sans surapprentissage (grâce au faible `shrinkage`).  \n",
    "2. **CV Robustesse** :  \n",
    "   - **RMSE CV = 15.9 ± 0.89** $\\rightarrow$ Très faible variabilité entre les folds, signe d’un modèle généralisable.  \n",
    "\n",
    "**Bilan** :\n",
    "Ces résultats positionnent **le GBM comme le modèle de référence pour la prédiction de `Calories_Burned`**, surpassant toutes les approches testées précédemment.\n",
    "\n",
    "Pour aller plus loin, nous allons maintenant :\n",
    "\n",
    "- Analyser les résidus : Vérifier l’absence de biais systématique même à haute intensité.  \n",
    "- Feature Importance : Visualiser l'évolution de la prédiction de `Calories_Burned` en fonction des variables les plus explicatives de ce modèle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fit.boostr.cal <- boost.reg.cal$fit\n",
    "res.boostr.cal <- fit.boostr.cal - gym_train[,\"Calories_Burned\"]\n",
    "gplot.res(fit.boostr.cal, res.boostr.cal, titre=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation des résidus** : Par rapport aux modèles précédents, les résidus du modèle de boosting sont beaucoup plus centrés autour de 0, avec une dispersion maximale de $\\pm 100$ calories. On remarque tout de même que :\n",
    "\n",
    "- la surestimation des valeurs prédites n'a lieu qu'entre 400 et 1500 calories mais pour les extrêmes (< 400 et > 1500 calories), le modèle sous-estime quasi-systemétiquement les calories brulées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# plot(gg_vimp(importance(boost.reg.cal)))\n",
    "# Get variable importance from the GBM model\n",
    "imp <- summary(boost.reg.cal, plotit = FALSE)\n",
    "\n",
    "# Create a ggplot of variable importance\n",
    "ggplot(imp, aes(x = reorder(var, rel.inf), y = rel.inf)) +\n",
    "    geom_bar(stat = \"identity\", fill = \"#777777\") +\n",
    "    coord_flip() +\n",
    "    labs(x = \"Variables\", y = \"Relative Influence\", \n",
    "             title = \"Variable Importance in GBM Model\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation des variables importantes** :\n",
    "\n",
    "Le GBM révèle une hiérarchie claire : `Session_Duration` (~80%) domine, suivie de `Avg_BPM` (~11%), confirmant les résultats de la forêt (`mtry=13`) et du Lasso. La faible importance de `SFat_Percentage` (~5%) et `Experience_Level` (~1%) suggère que leurs effets, bien que réels, sont majoritairement contextuels mais cela est à vérifier avec les partial dependence plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# PDP pour une variable (ex: Age)\n",
    "pdp1 <- partial(boost.reg.cal, pred.var = \"Session_Duration..hours.\", rug = TRUE, train=gym_train, type=\"regression\")\n",
    "pdp2 <- partial(boost.reg.cal, pred.var = \"Avg_BPM\", rug = TRUE, train=gym_train, type=\"regression\")\n",
    "pdp3 <- partial(boost.reg.cal, pred.var = \"SFat_Percentage\", rug = TRUE, train=gym_train, type=\"regression\")\n",
    "pdp4 <- partial(boost.reg.cal, pred.var = \"Age\", rug = TRUE, train=gym_train, type=\"regression\")\n",
    "pdp5 <- partial(boost.reg.cal, pred.var = \"Gender\", rug = TRUE, train=gym_train, type=\"regression\")\n",
    "\n",
    "p1 <- autoplot(pdp1)\n",
    "p2 <- autoplot(pdp2)\n",
    "p3 <- autoplot(pdp3)\n",
    "p4 <- autoplot(pdp4)\n",
    "p5 <- autoplot(pdp5)\n",
    "\n",
    "options(repr.plot.width=20, repr.plot.height=14)\n",
    "main = \"Partial Dependence Plots - Gradient Boosting Model\"\n",
    "grid.arrange(p1, p2, p3, p4, p5, ncol = 2, top = main)\n",
    "rm(p1, p2, p3, p4, p5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpetation des PDP**:\n",
    "\n",
    "Les partial dependence plots issus du modèle de Gradient Boosting permettent de visualiser l’impact isolé des variables sur la prédiction des calories brûlées. Ils confirment les résultats de l’analyse de l’importance des variables : \n",
    "\n",
    "- la durée de la séance (`Session_Duration..hours.`) et l’intensité de l’effort (`Avg_BPM`) sont les principaux déterminants avec des effets linéaires croissants. La durée de la séance a une influence de sur la variable cible, avec **un delta de 1000 calories entre les séances les plus courtes et les plus longues**. L’intensité de l’effort a également un impact significatif, avec **un delta de 400 calories entre les séances à 120 bpm et celles à 170 bpm** en moyenne. Ces résultats sont cohérents avec les analyses précédentes.\n",
    "- le pourcentage de masse grasse (`SFatPercentage`) et l'age (`Age`) des individus on des interactions non lineaires avec la dépense calorique. :\n",
    "  - En se remémorant la transformation de `FatPercentage`, les personnes **à faible taux de masse grasse ont une depense calorique plus importante** que les personnes à fort taux de masse grasse, **à effort égal**. \n",
    "  - Quant à l'age, on observe deux groupes : **les jeunes adultes (18-40 ans)** dépensent **près de 100 calories de plus** que **les personnes âgées entre 40 et 60 ans**, **à effort égal**. Ce résultat suggère un effet physiologique lié au vieillissement, notamment la perte de masse musculaire (sarcopénie), bien connue pour réduire la dépense énergétique. Cette hypothèse est cohérente avec les données scientifiques, qui montrent qu’à effort égal, un corps plus musclé consomme davantage de calories. Le modèle semble donc capter ici une relation non linéaire complexe entre l’âge, la composition corporelle et la dépense énergétique, malgré l’absence explicite de variable de masse musculaire dans le jeu de données. Il serait tout de même interessant de vérifier si la proportion de ces deux groupes de personnes est équilibrée dans le jeu de données, car il pourrait y avoir un biais de sélection.\n",
    "- le genre (`Gender`) présente un léger effet marginal : les hommes brûlent légèrement plus de calories que les femmes (~70 calories d'écart).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculer les proportions dans le jeu d'entraînement\n",
    "prop_train <- prop.table(table(ifelse(gym_train$Age > 40, \">40\", \"<=40\"))) * 100\n",
    "\n",
    "# Calculer les proportions dans le jeu de test\n",
    "prop_test <- prop.table(table(ifelse(gym_test$Age > 40, \">40\", \"<=40\"))) * 100\n",
    "\n",
    "# Afficher les proportions\n",
    "cat(\"Proportions dans le jeu d'entraînement:\")\n",
    "print(prop_train)\n",
    "\n",
    "cat(\"\\nProportions dans le jeu de test:\")\n",
    "print(prop_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "La répartition des âges est équilibrée (~52/48 % training, ~54/46 test), écartant l’hypothèse d’un biais de sélection. L’effet de l’âge observé dans le PDP reflète donc une tendance réelle, captée spécifiquement par le modèle de boosting — et non mise en évidence par les autres approches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
